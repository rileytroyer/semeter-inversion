{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a095a64",
   "metadata": {},
   "source": [
    "# Code to export pfisr data for SIC model run\n",
    "\n",
    "written by Riley Troyer Spring 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "147ba8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from datetime import datetime as dt\n",
    "import gc\n",
    "import h5py\n",
    "import msise00\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e8b95a",
   "metadata": {},
   "source": [
    "## The first thing I do is read in a config file with various parameters that I could change from run to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ee4b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in config file with dictionary of specified inputs\n",
    "import config_example as config\n",
    "config_data = config.run_info['config_info']\n",
    "\n",
    "# Path to pfisr data directory\n",
    "pfisr_data_dir = config_data['isr_data_dir']\n",
    "\n",
    "# File with times for events of interest\n",
    "reference_file = config_data['event_file']\n",
    "\n",
    "# Get location of PFISR\n",
    "pfrr_lat = config_data['isr_lat']\n",
    "pfrr_lon = config_data['isr_lon']\n",
    "\n",
    "# Define test flux in m^-2 s^-1\n",
    "F = config_data['test_flux']\n",
    "\n",
    "# Don't use PFISR data below this altitude in km\n",
    "pfisr_min_alt = config_data['isr_min_alt']\n",
    "\n",
    "# Get sensitivity limit of PFISR\n",
    "pfisr_sensitivity = config_data['isr_sensitivity']\n",
    "\n",
    "# Altitude in meters to approximate infinity when calculating\n",
    "#...mass distance\n",
    "max_msis_alt = config_data['max_msis_alt']\n",
    "\n",
    "# Maximum number of iterations to run maximum entropy process on\n",
    "max_iterations = config_data['max_iterations']\n",
    "\n",
    "# Reduced chi square to aim for\n",
    "convergence = config_data['convergence']\n",
    "\n",
    "# Define arrays for altitude and energy bins\n",
    "\n",
    "# Altitude in meters\n",
    "#...number of points should be around the same as pfisr data\n",
    "altitude_bins = config_data['altitude_bins']\n",
    "\n",
    "# Energies in eV\n",
    "#...should probably be less than altitude bins to avoid overfitting\n",
    "energy_bins = config_data['energy_bins']\n",
    "\n",
    "# Get which chemistry model to use\n",
    "alpha_type = config_data['alpha_type']\n",
    "\n",
    "# Get files to run code for\n",
    "pfisr_files = config.run_info['run_files']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "73d55992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example code just use one file\n",
    "#pfisr_filename = pfisr_files[0]\n",
    "#pfisr_filename = pfisr_files[12]\n",
    "pfisr_filename = pfisr_files[56]\n",
    "#pfisr_filename = '20080326.001_bc_1min-fitcal.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6df028fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20200104.001_bc_nenotr_1min.h5'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfisr_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04036c3d",
   "metadata": {},
   "source": [
    "## Next I read in a file containing the ISR data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ce81bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_isr_data(pfisr_filename, pfisr_data_dir):\n",
    "    \"\"\"Function to get relevant data from PFISR datafile.\n",
    "    INPUT\n",
    "    pfisr_filename\n",
    "        type: str\n",
    "        about: data file name, should be .h5 file\n",
    "    pfisr_data_dir\n",
    "        type: str\n",
    "        about: directory where isr data is stored\n",
    "    OUTPUT\n",
    "    utc_time\n",
    "        type: array of datetimes\n",
    "        about: time stamp for the start of each measurement\n",
    "    pfisr_altitude\n",
    "        type: array of float\n",
    "        about: altitude stamp for each measurement in meters\n",
    "    e_density\n",
    "        type: array of float\n",
    "        about: electron number density in m^-3\n",
    "    de_density\n",
    "        type: array of float\n",
    "        about: error in number density\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read in the h5 file\n",
    "    pfisr_file = h5py.File(pfisr_data_dir + pfisr_filename, 'r')\n",
    "\n",
    "    # Get the different beams and select specified angle\n",
    "    beam_angle = 90\n",
    "    beams = np.array(pfisr_file['BeamCodes'])\n",
    "\n",
    "    # Get the beam with a 90 degree elevation angle\n",
    "    indexes = np.linspace(0, len(beams)-1, len(beams))\n",
    "    beam_num = int(indexes[np.abs(beams[:,2] - beam_angle) == 0][0])\n",
    "\n",
    "    # Get time and convert to utc datetime\n",
    "    unix_time = np.array(pfisr_file['Time']['UnixTime'])[:,0]\n",
    "    utc_time = np.array([dt.utcfromtimestamp(d) for d in unix_time])\n",
    "\n",
    "    # Get the altitude array\n",
    "    pfisr_altitude = np.array(pfisr_file['NeFromPower']\n",
    "                              ['Altitude'])[beam_num, :]\n",
    "\n",
    "    # Get the uncorrected number density array\n",
    "    e_density = np.array(pfisr_file['NeFromPower']\n",
    "                         ['Ne_NoTr'])[:, beam_num, :]\n",
    "\n",
    "    # Take the transpose\n",
    "    e_density = np.transpose(e_density)\n",
    "    \n",
    "    # Find the noise floor by averaging between 55km and 60km\n",
    "    #...assume this should be zero\n",
    "    noise_floor = np.mean(e_density[(pfisr_altitude > 55000)\n",
    "                                    & (pfisr_altitude < 60000), :],\n",
    "                          axis=0)\n",
    "    \n",
    "    # Loop through each column and subtract off noise floor\n",
    "    for j in range(e_density.shape[1]):\n",
    "        e_density[:, j] = e_density[:, j] - noise_floor[j]\n",
    "    \n",
    "    # Get error values\n",
    "    try:\n",
    "        de_density = np.array(pfisr_file['NeFromPower']\n",
    "                              ['errNe_NoTr'])[:, beam_num, :]\n",
    "        de_density = np.transpose(de_density)\n",
    "    except:\n",
    "        de_density = np.array(pfisr_file['NeFromPower']\n",
    "                              ['dNeFrac'])[:, beam_num, :]\n",
    "        de_density = np.transpose(de_density)\n",
    "        de_density = de_density * e_density\n",
    "\n",
    "    # Close file\n",
    "    pfisr_file.close()\n",
    "    \n",
    "    return utc_time, unix_time, pfisr_altitude, e_density, de_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "201c09a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the pfisr data\n",
    "(utc_time, unix_time, \n",
    " pfisr_altitude,\n",
    " e_density, de_density) = get_isr_data(pfisr_filename, pfisr_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b0f4ab",
   "metadata": {},
   "source": [
    "## Events of interest are usually only a small portion of the ISR data, so to speed up the analysis it's useful to select only these periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "24dbb650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_event_indices(utc_time):\n",
    "    \"\"\"Function to find only indices of times of interest.\n",
    "    INPUT\n",
    "    utc_time\n",
    "        type: array of datetimes\n",
    "        about: utc datetimes of all pfisr data\n",
    "    OUTPUT\n",
    "    slices_n\n",
    "        type: list of integers\n",
    "        about: indices of pfisr data that is of interest\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find the date for the current pfisr file, this is a little tricky as\n",
    "    #...some pfisr files span multiple days\n",
    "    pfisr_dates = np.unique(np.array([d.date() for d in utc_time]))\n",
    "\n",
    "    # Dates that are in both pa database and pfisr file\n",
    "    pa_pfisr_dates = np.unique(np.array([d for d in pa_dates \n",
    "                                         if d in pfisr_dates]))\n",
    "\n",
    "    # Loop through each of these dates and get correct indices\n",
    "    indices = []\n",
    "    for date in pa_pfisr_dates:\n",
    "            indices.append(np.argwhere(pa_dates == date))\n",
    "\n",
    "    # Flatten list of indices\n",
    "    indices = [item[0] for sublist in indices for item in sublist]\n",
    "\n",
    "    # Loop through each index and get data slices corresponding to the\n",
    "    #...start and stop times\n",
    "    slices_n = []\n",
    "    for index in indices:\n",
    "\n",
    "        # Get the date and start time of measurements\n",
    "        date = pa_database[index, 0]\n",
    "        start_time = date + ' ' + pa_database[index, 1]\n",
    "        end_time = date + ' ' + pa_database[index, 2]\n",
    "\n",
    "        # Convert to datetime\n",
    "        start_time = dt.strptime(start_time, '%Y-%m-%d %H:%M:%S')\n",
    "        end_time = dt.strptime(end_time, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        # Find which indices in pfisr data correspond\n",
    "        slices_n.append(np.argwhere((utc_time >= start_time) \n",
    "                                    & (utc_time <= end_time)))\n",
    "\n",
    "    # Flatten pfisr array indices\n",
    "    slices_n = [item[0] for sublist in slices_n for item in sublist]\n",
    "    \n",
    "    return slices_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "29d4b6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in file with pulsating aurora dates, times and types\n",
    "pa_database = np.loadtxt(reference_file, delimiter='\\t', dtype=str)\n",
    "pa_database = pa_database[1:, :]\n",
    "\n",
    "# Convert dates to datetimes\n",
    "pa_dates = np.array([dt.strptime(d, '%Y-%m-%d').date() for d \n",
    "                     in pa_database[:, 0]])\n",
    "\n",
    "slices_n = find_event_indices(utc_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b71b3b3",
   "metadata": {},
   "source": [
    "## Get only a single slice of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "154681eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-04 11:49:37\n"
     ]
    }
   ],
   "source": [
    "# Time slice to run inversion for\n",
    "#slice_n = 684\n",
    "slice_n = 46\n",
    "print(utc_time[slice_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a0288e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time associated with slice\n",
    "run_time = utc_time[slice_n]\n",
    "\n",
    "# Get PFISR data for slice\n",
    "\n",
    "# Read in density and errors in those measurements\n",
    "#...for specific time\n",
    "e_density_slice = e_density[:, slice_n]\n",
    "de_density_slice = de_density[:, slice_n]\n",
    "\n",
    "# Make interpolation model of this data with respect to altitude\n",
    "#...but only do this for altitudes > defined minimum value,\n",
    "#...below this data can be weird\n",
    "pfisr_density_interp = interp1d(pfisr_altitude, e_density_slice)\n",
    "\n",
    "# Same interpolation except for error in density\n",
    "pfisr_error_interp = interp1d(pfisr_altitude, de_density_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5266de86",
   "metadata": {},
   "source": [
    "## Write the data to an excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e85d8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to include in dataframe\n",
    "d = {'UTC': run_time,\n",
    "     'Geographic Latitude': pfrr_lat,\n",
    "     'Geographic Longitude' : pfrr_lon,\n",
    "     'Altitude (m)' : altitude_bins,\n",
    "     'Electron Density (m^-3)': pfisr_density_interp(altitude_bins)}\n",
    "\n",
    "# Create the dataframe\n",
    "pfisr_sic_data = pd.DataFrame(data = d)\n",
    "\n",
    "# Write to csv file\n",
    "csv_filename = '../source-energy-pa/data/pfisr-data/data-for-sic/time4.csv'\n",
    "pfisr_sic_data.to_csv(csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b71058",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
