{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41032afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'ignore', 'over': 'warn', 'under': 'ignore', 'invalid': 'ignore'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Code to run electon density -> energy inversion as per Semeter, Kamalabadi 2005 for PFISR data for specified number of days\n",
    "# \n",
    "# written by Riley Troyer Fall 2021\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "# Libraries\n",
    "import datetime\n",
    "from datetime import datetime as dt\n",
    "import gc\n",
    "import h5py\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors\n",
    "import msise00\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import scipy.stats\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.signal import savgol_coeffs\n",
    "from scipy.integrate import trapezoid\n",
    "\n",
    "# This might set off some warnings, but I think they can be ignored\n",
    "from kaeppler_chemistry import Chemistry as chemistry\n",
    "\n",
    "# Disable divide by zero numpy warnings\n",
    "np.seterr(divide='ignore')\n",
    "np.seterr(invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b30ba80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[2]:\n",
    "\n",
    "\n",
    "# Read in config file with dictionary of specified inputs\n",
    "import config_2022_05_25 as config\n",
    "config_data = config.run_info['config_info']\n",
    "\n",
    "# Path to pfisr data directory\n",
    "pfisr_data_dir = config_data['isr_data_dir']\n",
    "\n",
    "# File with times for events of interest\n",
    "reference_file = config_data['event_file']\n",
    "\n",
    "# Directory to save files to\n",
    "save_dir = config_data['save_dir']\n",
    "\n",
    "# Get location of PFISR\n",
    "pfrr_lat = config_data['isr_lat']\n",
    "pfrr_lon = config_data['isr_lon']\n",
    "\n",
    "# Define test flux in m^-2 s^-1\n",
    "F = config_data['test_flux']\n",
    "\n",
    "# Don't use PFISR data below this altitude in km\n",
    "pfisr_min_alt = config_data['isr_min_alt']\n",
    "\n",
    "# Get sensitivity limit of PFISR\n",
    "pfisr_sensitivity = config_data['isr_sensitivity']\n",
    "\n",
    "# Altitude in meters to approximate infinity when calculating\n",
    "#...mass distance\n",
    "max_msis_alt = config_data['max_msis_alt']\n",
    "\n",
    "# Maximum number of iterations to run maximum entropy process on\n",
    "max_iterations = config_data['max_iterations']\n",
    "\n",
    "# Reduced chi square to aim for\n",
    "convergence = config_data['convergence']\n",
    "\n",
    "# Define arrays for altitude and energy bins\n",
    "\n",
    "# Altitude in meters\n",
    "#...number of points should be around the same as pfisr data\n",
    "altitude_bins = config_data['altitude_bins']\n",
    "\n",
    "# Energies in eV\n",
    "#...should probably be less than altitude bins to avoid overfitting\n",
    "energy_bins = config_data['energy_bins']\n",
    "\n",
    "# Get which chemistry model to use\n",
    "alpha_type = config_data['alpha_type']\n",
    "\n",
    "# Get files to run code for\n",
    "pfisr_files = config.run_info['run_files']\n",
    "\n",
    "pfisr_files = ['20220305.001_bc_nenotr_1min.h5']#pfisr_files[43:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa990611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[3]:\n",
    "\n",
    "\n",
    "def barrett_hays_range_energy_func(K):\n",
    "    \"\"\"Function to define mass range of electron in air for a specific\n",
    "    energy K in eV. From Barett & Hays 1976\n",
    "    INPUT\n",
    "    K\n",
    "        type: float\n",
    "        about: energy of electron in eV\n",
    "    OUTPUT\n",
    "    R\n",
    "        type: float\n",
    "        about: mass range of particle in kg m^-2 \n",
    "    \"\"\"\n",
    "    # Convert energy to keV to match formula\n",
    "    K = K/1000\n",
    "    \n",
    "    # Range function\n",
    "    R = 4.3e-7 + 5.36e-6 * K**(1.67) - 0.38e-8 * K**(-0.7)\n",
    "    \n",
    "    # Convert R from g/cm^2 to kg/m^2\n",
    "    R = R * 10\n",
    "    \n",
    "    return R\n",
    "\n",
    "def estimate_initial_number_flux(energy_bins, matrix_A):\n",
    "    \"\"\"Function to estimate the intial number flux for each energy bin\n",
    "    INPUT\n",
    "    energy_bins\n",
    "        type: array of float\n",
    "        about: energy values defining energy bins\n",
    "    matrix_A\n",
    "        type: array of float\n",
    "        about: inversion matrix\n",
    "    OUTPUT\n",
    "    initial_num_flux\n",
    "        type: array of float\n",
    "        about: estimated number flux in m^-2 s^-1 for each energy bin\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make an initial guess of the number flux\n",
    "    initial_num_flux = np.ones(len(energy_bins))*(1e12/len(energy_bins))\n",
    "\n",
    "    # Divide by energy bin widths\n",
    "    bin_widths = energy_bins - np.roll(energy_bins, shift=1)\n",
    "\n",
    "    # Fix first value\n",
    "    bin_widths[0] = energy_bins[0] - 0\n",
    "\n",
    "    # Set initial guess\n",
    "    initial_num_flux = initial_num_flux/bin_widths\n",
    "\n",
    "    # If full column of A matrix is zero set initial flux to zero\n",
    "    for j in range(len(energy_bins)):\n",
    "\n",
    "        if np.sum(matrix_A[:, j]) == 0:\n",
    "            initial_num_flux[j] = 0\n",
    "            \n",
    "    return initial_num_flux\n",
    "\n",
    "def find_event_indices(utc_time):\n",
    "    \"\"\"Function to find only indices of times of interest.\n",
    "    INPUT\n",
    "    utc_time\n",
    "        type: array of datetimes\n",
    "        about: utc datetimes of all pfisr data\n",
    "    OUTPUT\n",
    "    slices_n\n",
    "        type: list of integers\n",
    "        about: indices of pfisr data that is of interest\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find the date for the current pfisr file, this is a little tricky as\n",
    "    #...some pfisr files span multiple days\n",
    "    pfisr_dates = np.unique(np.array([d.date() for d in utc_time]))\n",
    "\n",
    "    # Dates that are in both pa database and pfisr file\n",
    "    pa_pfisr_dates = np.unique(np.array([d for d in pa_dates \n",
    "                                         if d in pfisr_dates]))\n",
    "\n",
    "    # Loop through each of these dates and get correct indices\n",
    "    indices = []\n",
    "    for date in pa_pfisr_dates:\n",
    "            indices.append(np.argwhere(pa_dates == date))\n",
    "\n",
    "    # Flatten list of indices\n",
    "    indices = [item[0] for sublist in indices for item in sublist]\n",
    "\n",
    "    # Loop through each index and get data slices corresponding to the\n",
    "    #...start and stop times\n",
    "    slices_n = []\n",
    "    for index in indices:\n",
    "\n",
    "        # Get the date and start time of measurements\n",
    "        date = pa_database[index, 0]\n",
    "        start_time = date + ' ' + pa_database[index, 1]\n",
    "        end_time = date + ' ' + pa_database[index, 2]\n",
    "\n",
    "        # Convert to datetime\n",
    "        start_time = dt.strptime(start_time, '%Y-%m-%d %H:%M:%S')\n",
    "        end_time = dt.strptime(end_time, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        # Find which indices in pfisr data correspond\n",
    "        slices_n.append(np.argwhere((utc_time >= start_time) \n",
    "                                    & (utc_time <= end_time)))\n",
    "\n",
    "    # Flatten pfisr array indices\n",
    "    slices_n = [item[0] for sublist in slices_n for item in sublist]\n",
    "    \n",
    "    return slices_n\n",
    "\n",
    "def get_isr_data(pfisr_filename, pfisr_data_dir):\n",
    "    \"\"\"Function to get relevant data from PFISR datafile.\n",
    "    INPUT\n",
    "    pfisr_filename\n",
    "        type: str\n",
    "        about: data file name, should be .h5 file\n",
    "    pfisr_data_dir\n",
    "        type: str\n",
    "        about: directory where isr data is stored\n",
    "    OUTPUT\n",
    "    utc_time\n",
    "        type: array of datetimes\n",
    "        about: time stamp for the start of each measurement\n",
    "    unix_time\n",
    "        type: array of floats\n",
    "        about: unix timestamp for start of each measurement\n",
    "    pfisr_altitude\n",
    "        type: array of float\n",
    "        about: altitude stamp for each measurement in meters\n",
    "    e_density\n",
    "        type: array of float\n",
    "        about: electron number density in m^-3\n",
    "    de_density\n",
    "        type: array of float\n",
    "        about: error in number density\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read in the h5 file\n",
    "    pfisr_file = h5py.File(pfisr_data_dir + pfisr_filename, 'r')\n",
    "\n",
    "    # Get the different beams and select specified angle\n",
    "    beam_angle = 90\n",
    "    beams = np.array(pfisr_file['BeamCodes'])\n",
    "\n",
    "    # Get the beam with a 90 degree elevation angle\n",
    "    indexes = np.linspace(0, len(beams)-1, len(beams))\n",
    "    beam_num = int(indexes[np.abs(beams[:,2] - beam_angle) == 0][0])\n",
    "\n",
    "    # Get time and convert to utc datetime\n",
    "    unix_time = np.array(pfisr_file['Time']['UnixTime'])[:,0]\n",
    "    utc_time = np.array([datetime.datetime.utcfromtimestamp(d) \n",
    "                         for d in unix_time])\n",
    "\n",
    "    # Get the altitude array\n",
    "    pfisr_altitude = np.array(pfisr_file['NeFromPower']\n",
    "                              ['Altitude'])[beam_num, :]\n",
    "\n",
    "    # Get the uncorrected number density array\n",
    "    e_density = np.array(pfisr_file['NeFromPower']\n",
    "                         ['Ne_NoTr'])[:, beam_num, :]\n",
    "\n",
    "    # Take the transpose\n",
    "    e_density = np.transpose(e_density)\n",
    "    \n",
    "    # Find the noise floor by averaging between 55km and 60km\n",
    "    #...assume this should be zero\n",
    "    \n",
    "    # Calculate the power given that power = density/range^2\n",
    "    pfisr_range = np.array(pfisr_file['NeFromPower']\n",
    "                           ['Range'])[0, :]\n",
    "\n",
    "    # Turn 1D array into 2D array for elementwise division\n",
    "    pfisr_range = np.array([pfisr_range,]*e_density.shape[1])\n",
    "    pfisr_range = np.transpose(pfisr_range)\n",
    "    pfisr_power = np.divide(e_density, pfisr_range**2)\n",
    "\n",
    "    # Get the power bias\n",
    "    noise_floor = np.nanmean(pfisr_power[(pfisr_altitude > 55000)\n",
    "                                    & (pfisr_altitude < 60000), :],\n",
    "                              axis=0)\n",
    "    \n",
    "    # Only apply correction to lower altitudes\n",
    "    low_fade = 90e3\n",
    "    high_fade = 120e3\n",
    "    correction_fade = np.ones(len(pfisr_altitude))\n",
    "\n",
    "    # Fade from 1 to 0 over 90 to 120km\n",
    "    fade_selector = (pfisr_altitude > low_fade) & (pfisr_altitude < high_fade)\n",
    "    fade_len = len(fade_selector[fade_selector == True])\n",
    "    fade = np.linspace(1, 0, fade_len)\n",
    "\n",
    "    # Set correct fade values\n",
    "    correction_fade[fade_selector] = fade\n",
    "    correction_fade[pfisr_altitude > high_fade] = 0\n",
    "    \n",
    "\n",
    "    # Loop through each column and subtract off noise floor\n",
    "    for j in range(pfisr_power.shape[1]):\n",
    "        pfisr_power[:, j] = pfisr_power[:, j] - noise_floor[j]*correction_fade   \n",
    "\n",
    "    # Calculate new unbiased density\n",
    "    e_density = np.multiply(pfisr_power, pfisr_range**2)\n",
    "        \n",
    "    \n",
    "    # Get error values\n",
    "    try:\n",
    "        de_density = np.array(pfisr_file['NeFromPower']\n",
    "                              ['errNe_NoTr'])[:, beam_num, :]\n",
    "        de_density = np.transpose(de_density)\n",
    "    except:\n",
    "        de_density = np.array(pfisr_file['NeFromPower']\n",
    "                              ['dNeFrac'])[:, beam_num, :]\n",
    "        de_density = np.transpose(de_density)\n",
    "        de_density = de_density * e_density\n",
    "\n",
    "    # Close file\n",
    "    pfisr_file.close()\n",
    "    \n",
    "    return utc_time, unix_time, pfisr_altitude, e_density, de_density\n",
    "\n",
    "def get_msis_density(run_time, altitude_bins, max_alt=1001e3,\n",
    "                     glat=65.117, glon=212.540):\n",
    "    \"\"\"Function to get MSIS calculated atmospheric densities.\n",
    "    DEPENDENCIES\n",
    "        msise00, numpy, scipy.interpolate.interp1d\n",
    "    INPUT\n",
    "    run_time\n",
    "        type: datetime\n",
    "        about: time to run msis code for\n",
    "    altitudes\n",
    "        type: array of floats\n",
    "        about: altitudes in meters to run msis code for\n",
    "    max_alt = 1001e3\n",
    "        type: float\n",
    "        about: maximum altitude in meters to run msis for. \n",
    "               Function creates a high altitude log spaced array\n",
    "               between the max of altitudes and the max_alt value.\n",
    "               This is primarily for approximating an indefinite integral.\n",
    "    OUTPUT\n",
    "    total_msis_alt\n",
    "        type: array of floats\n",
    "        about: altitudes values in meters including original array and\n",
    "               high altitude array\n",
    "    msis_interp_density\n",
    "        type: scipy.interplate function\n",
    "        about: 1d interpolation of msis density spanning entire altitude\n",
    "               range.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Run msis for lower altitudes\n",
    "    msis_run_low = msise00.run(time=run_time, altkm=altitude_bins/1000,\n",
    "                               glat=pfrr_lat, glon=pfrr_lon)\n",
    "\n",
    "    # Define a higher altitude array\n",
    "    msis_alt_high = np.logspace(np.log10(max(altitude_bins)+1),\n",
    "                                np.log10(max_alt), 20)\n",
    "    \n",
    "    # Run msis for these higher altitudes\n",
    "    msis_run_high = msise00.run(time=run_time, altkm=msis_alt_high/1000,\n",
    "                               glat=pfrr_lat, glon=pfrr_lon)\n",
    "\n",
    "    # Get total density data\n",
    "    msis_density_low = msis_run_low['Total'].data[0, :, 0, 0]\n",
    "    msis_density_high = msis_run_high['Total'].data[0, :, 0, 0]\n",
    "\n",
    "    # Combine altitude and densities from low and high altitudes\n",
    "    total_msis_alt = np.concatenate((altitude_bins, msis_alt_high))\n",
    "    total_msis_density = np.concatenate((msis_density_low,\n",
    "                                         msis_density_high))\n",
    "\n",
    "    # Create a scipy interpolation function to define density v. altitude\n",
    "    msis_interp_density = interp1d(total_msis_alt, total_msis_density)\n",
    "    \n",
    "    return total_msis_alt, msis_interp_density\n",
    "\n",
    "def isr_ion_production_rate(slice_n, alpha_type='vickrey'):\n",
    "    \"\"\"Function to estimate the ion production rate from isr measurements.\n",
    "    There are many ways to do this that use differing chemistry\n",
    "    assumptions. Vickrey 1982 is a very basic assumption for the \n",
    "    E-region and is extended to D-region. Gledhill 1986 is slightly more\n",
    "    sophisticated using a best fit of many D-region measurements during\n",
    "    night time aurora. Osepian 2009 is based on measurements during \n",
    "    solar proton events. The Stanford model is based on the chemistry\n",
    "    model of Lehtinen 2007. \n",
    "    INPUT\n",
    "    slice_n\n",
    "        type: integer\n",
    "        about: data slice of isr data to take\n",
    "    alpha_type = 'vickrey'\n",
    "        type: string\n",
    "        about: what recombination coefficient to use\n",
    "                other option: osepian, gledhill, stanford\n",
    "    OUTPUT\n",
    "    q_estimate\n",
    "        type: array of float\n",
    "        about: estimated ion production rate m^-2 s^-1\n",
    "    dq_estimate\n",
    "        type: array of float\n",
    "        about: error in ion production rate\n",
    "    alphas\n",
    "        type: array of float\n",
    "        about: recombination coefficients\n",
    "    \"\"\"\n",
    "\n",
    "    if ((alpha_type=='vickrey')\n",
    "        or (alpha_type=='osepian')\n",
    "        or (alpha_type=='gledhill')):\n",
    "        # Read in density and errors in those measurements \n",
    "        #...for specific time\n",
    "        e_density_slice = e_density[:, slice_n]\n",
    "        de_density_slice = de_density[:, slice_n]\n",
    "\n",
    "        # Make interpolation model of this data with respect to altitude\n",
    "        #...but only do this for altitudes > defined minimum value,\n",
    "        #...below this data can be weird\n",
    "        pfisr_density_interp = interp1d(pfisr_altitude, e_density_slice)\n",
    "\n",
    "        # Same interpolation except for error in density\n",
    "        pfisr_error_interp = interp1d(pfisr_altitude, de_density_slice)\n",
    "\n",
    "        # Calculate all recombination coeffcients\n",
    "        alphas = np.array([recombination_coeff(z/1000,\n",
    "                                               alpha_type=alpha_type)\n",
    "                           for z in altitude_bins])\n",
    "\n",
    "        # Multiply by pfisr density to get estimate of production rate\n",
    "        #...keep sign in calculation, so don't bias high\n",
    "        pfisr_signs = np.sign(pfisr_density_interp(altitude_bins))\n",
    "        q_estimate = (alphas \n",
    "                      * pfisr_density_interp(altitude_bins)**2)\n",
    "\n",
    "        # Get error dq = 2*alpha*n*dn\n",
    "        dq_estimate = (2 * alphas * pfisr_density_interp(altitude_bins)\n",
    "                       * pfisr_error_interp(altitude_bins))\n",
    "        dq_estimate = abs(dq_estimate)\n",
    "    \n",
    "    elif alpha_type=='stanford':\n",
    "        # Read in the chemistry class\n",
    "        chem = chemistry(SteadyStateTime = 100., ISRIntegrationTime = 60.)\n",
    "\n",
    "        # Read in density and errors in those measurements\n",
    "        #...for specific time\n",
    "        e_density_slice = e_density[:, slice_n]\n",
    "        de_density_slice = de_density[:, slice_n]\n",
    "\n",
    "        # Make interpolation model of this data with respect to altitude\n",
    "        #...but only do this for altitudes > defined minimum value,\n",
    "        #...below this data can be weird\n",
    "        pfisr_density_interp = interp1d(pfisr_altitude, e_density_slice)\n",
    "\n",
    "        # Same interpolation except for error in density\n",
    "        pfisr_error_interp = interp1d(pfisr_altitude, de_density_slice)\n",
    "\n",
    "        # Multiply by pfisr density to get estimate of production rate\n",
    "        #...keep sign in calculation, so don't bias high\n",
    "        pfisr_signs = np.sign(pfisr_density_interp(altitude_bins))\n",
    "\n",
    "        # Initialize ionization in chemistry class\n",
    "        #...input altitude in km and stepsize of altitude bins required\n",
    "        alt_step = altitude_bins[1] - altitude_bins[0]\n",
    "        chem.Set_Inital_Ionization(unix_time[slice_n],\n",
    "                                   pfrr_lat, pfrr_lon,\n",
    "                                   min(altitude_bins)/1000,\n",
    "                                   max(altitude_bins)/1000,\n",
    "                                   alt_step/1000)\n",
    "\n",
    "        # Run chemistry code to convert density to ionization rate.\n",
    "        #...make sure to run initial ionziation code first\n",
    "        #...input should be in km and 1/cm^3\n",
    "        #...this will output in units of cgs\n",
    "        q_estimate = chem.Calculate_Ionization_From_Ne(altitude_bins/1000,\n",
    "                                pfisr_density_interp(altitude_bins)/1e6,\n",
    "                                chem.DregionChem)\n",
    "\n",
    "        # Add back in negatives and convert to SI\n",
    "        q_estimate = q_estimate * pfisr_signs * 1e6\n",
    "\n",
    "        # Calculate the extracted effective recombination coefficient\n",
    "        alphas = q_estimate / pfisr_density_interp(altitude_bins)**2\n",
    "        \n",
    "        # Match Gledhill above 90 km\n",
    "        e_region_cond = altitude_bins >= 90e3\n",
    "        alphas[e_region_cond] = [recombination_coeff(z/1000,\n",
    "                                               alpha_type='gledhill')\n",
    "                                 for z in altitude_bins[e_region_cond]]\n",
    "        \n",
    "        # Recalculate ion production rate\n",
    "        q_estimate = alphas * pfisr_density_interp(altitude_bins)**2\n",
    "\n",
    "        # Get error dq = 2*alpha*n*dn\n",
    "        dq_estimate = (2 * alphas\n",
    "                       * pfisr_density_interp(altitude_bins)\n",
    "                       * pfisr_error_interp(altitude_bins))\n",
    "        dq_estimate = abs(dq_estimate)\n",
    "        \n",
    "    else:\n",
    "        print('Enter good alpha type.')\n",
    "\n",
    "    \n",
    "    return q_estimate, dq_estimate, alphas\n",
    "\n",
    "def mass_distance(z_i, I=0):\n",
    "    \"\"\"Function to mass distance of particle traveling some distance\n",
    "    into the atmosphere. Denoted s in the derivations.\n",
    "    Using trapezoid rule for this, which seems to be good enough\n",
    "    INPUT\n",
    "    z\n",
    "        type: int\n",
    "        about: index of altitude that particle reached to\n",
    "    I=0\n",
    "        type: float\n",
    "        about: angle of magnetic inclination at measuring site in radians\n",
    "    OUTPUT\n",
    "    s\n",
    "        type: float\n",
    "        about: mass distance in kg m^-2\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate mass distance traveled \n",
    "    s = (1/np.cos(I)) * trapezoid(total_msis_density[z_i:],\n",
    "                                  total_msis_alt[z_i:])\n",
    "    \n",
    "    return s\n",
    "\n",
    "def maximum_entropy_iteration(initial_num_flux, altitude_bins,\n",
    "                              energy_bins,matrix_A,\n",
    "                              q_estimate, dq_estimate):\n",
    "    \"\"\"Function to peform the maximum entropy iterative process to\n",
    "    approximate inversion of matrix A. \n",
    "    Process is outlined in Semeter & Kamalabadi 2005.\n",
    "    INPUT\n",
    "    initial_num_flux\n",
    "        type: array of float\n",
    "        about: initial guess of number flux for each energy bin \n",
    "               in m^-2 s^-1\n",
    "    altitude_bins\n",
    "        type: array of float\n",
    "        about: altitude values in meters defining altitude bins\n",
    "    energy_bins\n",
    "        type: array of float\n",
    "        about: energy values in eV defining energy bins\n",
    "    matrix_A\n",
    "        type: array of float\n",
    "        about: matrix that iteration is trying to invert\n",
    "    q_estimate\n",
    "        type: array of float\n",
    "        about: estimated ion production rate from ISR m^-2 s^-1\n",
    "    dq_estimate\n",
    "        type: array of float\n",
    "        about: error in ion production rate of ISR\n",
    "    OUTPUT\n",
    "    new_num_flux\n",
    "        type: array of float\n",
    "        about: estimated number flux for energy bins in m^-2 s^-1\n",
    "    reduced_chi_square\n",
    "        type: float\n",
    "        about: error in modeled fit\n",
    "    good_alt_index\n",
    "        type: int\n",
    "        about: lower than this won't be good data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set previous value to initial at start\n",
    "    old_num_flux = initial_num_flux\n",
    "    new_num_flux = np.zeros(len(initial_num_flux))  \n",
    "    \n",
    "    # Create array to store all minimum j values\n",
    "    min_js = np.zeros(len(altitude_bins), dtype=int)\n",
    "\n",
    "    # Find all nonzero indices of A matrix\n",
    "    nonzero_args = np.argwhere(matrix_A > 0)\n",
    "\n",
    "    for i in range(len(min_js)):\n",
    "\n",
    "        non_zeros = nonzero_args[nonzero_args[:, 0] == i]\n",
    "\n",
    "        # If there are no non zero values in row, then set to \n",
    "        #...first instance\n",
    "        if len(non_zeros) == 0:\n",
    "            min_js[i] = 0\n",
    "\n",
    "        # Otherwise find the minimum j\n",
    "        else:\n",
    "            min_js[i] = min(non_zeros[:, 1])\n",
    "\n",
    "    # Initialize values\n",
    "    old_chi_square = 1e3\n",
    "    chi_square = 0\n",
    "    old_chi2_diff = 1e9\n",
    "    converged = True\n",
    "    count = 0\n",
    "\n",
    "    # Run interations until convergence or count is met\n",
    "    while (old_chi2_diff > convergence):\n",
    "\n",
    "        # Check count\n",
    "        if count > max_iterations:\n",
    "            print('Slice: {slice_n}. '\n",
    "                  'Unable to converge. '\n",
    "                  'Max iterations reached with chi2 = {chi2}'\n",
    "                  .format(slice_n=slice_n,\n",
    "                          chi2=round(chi_square, 2)))\n",
    "            break\n",
    "\n",
    "        # Construct the t vector\n",
    "        t = 1/np.dot(matrix_A[:, min_js], old_num_flux[min_js])\n",
    "\n",
    "        # Adjust for infinite values in regions without a nonzero j\n",
    "        t[t == np.inf] = 0        \n",
    "\n",
    "        for j in range(len(energy_bins)):\n",
    "\n",
    "            # Construct c vector\n",
    "            frac = np.inner(matrix_A, old_num_flux)/q_estimate\n",
    "            c = 20 * (1 - frac) * t\n",
    "\n",
    "            # Account for nan and infinite values\n",
    "            #...this is why warning is raised\n",
    "            c[np.isnan(c)] = 0\n",
    "            c[c == -np.inf] = 0\n",
    "            c[c == np.inf] = 0\n",
    "\n",
    "            # Define w constant\n",
    "            w = np.ones(len(altitude_bins))/len(altitude_bins)\n",
    "\n",
    "            # Summation of matrix elements\n",
    "            i_sum = np.sum(w*c*matrix_A[:, j])\n",
    "\n",
    "            # New guess\n",
    "            new_num_flux[j] = old_num_flux[j]/(1-old_num_flux[j]*i_sum)\n",
    "\n",
    "        # Check chi squared, but only on altitudes that A is defined for\n",
    "        diff=q_estimate-np.dot(matrix_A, new_num_flux)\n",
    "        chi_square_array = diff**2/dq_estimate**2\n",
    "\n",
    "        # Set undefined values to zero\n",
    "        chi_square_array[np.isnan(chi_square_array)] = 0\n",
    "        chi_square_array[chi_square_array == np.inf] = 0\n",
    "        chi_square_array[chi_square_array == -np.inf] = 0\n",
    "        \n",
    "        # Get the chi squared value\n",
    "        chi_square = np.sum(chi_square_array)\n",
    "        \n",
    "        # Do a convergence test, make sure it isn't blowing up\n",
    "        if (old_chi2_diff \n",
    "            < abs(old_chi_square - chi_square)) & (count > 1000):\n",
    "            print('Slice: {slice_n}. '\n",
    "                  'Not converging. Stopping. '\n",
    "                  'chi2 = {chi2}'\n",
    "                  .format(slice_n=slice_n,\n",
    "                          chi2=round(chi_square, 2)))\n",
    "            converged = False\n",
    "            break \n",
    "\n",
    "        # Set old values to new\n",
    "        old_num_flux = np.copy(new_num_flux)\n",
    "        old_chi2_diff = abs(old_chi_square - chi_square)\n",
    "        old_chi_square = chi_square\n",
    "\n",
    "        # Set count\n",
    "        count = count + 1\n",
    "        \n",
    "    # Get reduced chi square, which should be around 1\n",
    "    diff=q_estimate-np.dot(matrix_A, new_num_flux)\n",
    "    dof = len(q_estimate[dq_estimate < q_estimate]) - matrix_A.shape[1]\n",
    "    \n",
    "    # Notify of convergence\n",
    "    if ((count < max_iterations) & (converged == True)):\n",
    "        print('Slice: {slice_n}. '\n",
    "              'Convergence reached. '\n",
    "              'Iterations: {count}. '\n",
    "              'reduced chi2: {chi2}'.format(slice_n=slice_n, \n",
    "                                            count=count-1,\n",
    "                                            chi2=round(chi_square/dof, 2))\n",
    "             )\n",
    "        \n",
    "    return new_num_flux, chi_square, dof, converged\n",
    "\n",
    "def recombination_coeff(z, alpha_type='vickrey'):\n",
    "    \"\"\"Function defining recombination coefficient\n",
    "    INPUT\n",
    "    z\n",
    "        type:float\n",
    "        about: altitude in kilometers\n",
    "    alpha_type = 'vickrey'\n",
    "        type: string\n",
    "        about: what recombination coefficient to use\n",
    "                other option: osepian, gledhill\n",
    "    OUTPUT\n",
    "    alpha\n",
    "        type: float\n",
    "        about: recombination coefficient in m^3/s\n",
    "    \"\"\"\n",
    "    \n",
    "    if alpha_type == 'vickrey':\n",
    "        \n",
    "        alpha = 2.5e-12 * np.exp(-z/51.2)\n",
    "    \n",
    "    if alpha_type == 'osepian':\n",
    "        \n",
    "        # Read in file with effective recombination coefficient values\n",
    "        alpha_filename = 'effective-recombination-coefficient.txt'\n",
    "        alpha_data = np.loadtxt(alpha_filename, skiprows=6)\n",
    "\n",
    "        # Get altitude and coeff from data\n",
    "        alpha_alt = alpha_data[:, 0]\n",
    "        alpha_coeff = alpha_data[:, 1]*1e-6\n",
    "\n",
    "        # Append formula value at 144 km\n",
    "        alpha_alt = np.append(alpha_alt, 144)\n",
    "        alpha_coeff = np.append(alpha_coeff, recombination_coeff(144))\n",
    "\n",
    "        # Create an interpolated function from this\n",
    "        #...values outside set to 0\n",
    "        alpha_interp = interp1d(alpha_alt, alpha_coeff,\n",
    "                                 bounds_error=False, fill_value=0)  \n",
    "        \n",
    "        alpha = alpha_interp(z)\n",
    "    \n",
    "    if alpha_type == 'gledhill':\n",
    "        \n",
    "        alpha = (4.3e-6 * np.exp(-2.42e-2 * z) \n",
    "                 + 8.16e12 * np.exp(-0.524 * z))\n",
    "        \n",
    "        # Convert to m^3\n",
    "        alpha = alpha * 1e-6\n",
    "    \n",
    "    return alpha\n",
    "\n",
    "def save_inversion_density_plot(inversion_results, run_time, output_dir):\n",
    "    \"\"\"Function to create and save a plot of the inversion \n",
    "    electron density.\n",
    "    INPUT\n",
    "    inversion_results\n",
    "        type: dictionary\n",
    "        about: dictionary of inversion results\n",
    "    run_time\n",
    "        type: datetime\n",
    "        about: time to create plot for\n",
    "    output_dir\n",
    "        type: str\n",
    "        about: where to store the images\n",
    "    OUTPUT\n",
    "    none\n",
    "    \"\"\"\n",
    "    # Get altitude values\n",
    "    altitude_bins = inversion_results[run_time]['altitude']\n",
    "\n",
    "    # Get measured density\n",
    "    pfisr_density_plot = inversion_results[run_time]['measured_density']\n",
    "    pfisr_density_plot = pfisr_density_plot\n",
    "\n",
    "    # Initial guess\n",
    "    initial_guess_plot = inversion_results[run_time]['initial_density']\n",
    "    initial_guess_plot = initial_guess_plot\n",
    "    \n",
    "    # Finally modeled guess\n",
    "    final_guess_plot = inversion_results[run_time]['modeled_density']\n",
    "    final_guess_plot = final_guess_plot\n",
    "    \n",
    "    # Get reduced chi2\n",
    "    chi2 = inversion_results[run_time]['chi2']\n",
    "    dof = inversion_results[run_time]['dof']\n",
    "    reduced_chi2 = chi2/dof\n",
    "\n",
    "    # Plot figure of initial guess, real data and fit\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Titles and axis labels\n",
    "    ax.set_title(str(run_time) + r' $\\chi^2_{red}=$' \n",
    "                 + str(round(reduced_chi2, 2)),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "    ax.set_ylabel('Altitude [km]', fontsize=14)\n",
    "    ax.set_xlabel(r'Electron Density [m$^{-3}$]', fontsize=14)\n",
    "\n",
    "    # Axis\n",
    "    ax.tick_params(axis='x', which='major', labelsize=14)\n",
    "    ax.tick_params(axis='y', which='major', labelsize=14)\n",
    "\n",
    "    ax.set_xscale('log')\n",
    "    #ax.set_xlim(1e10, 1e12)\n",
    "    #ax.set_ylim(75, 140)\n",
    "\n",
    "    # Plot PFISR data\n",
    "    ax.plot(pfisr_density_plot, altitude_bins/1000,\n",
    "            color='k', linewidth=2, label = 'PFISR')\n",
    "\n",
    "    # Plot initial guess\n",
    "    ax.plot(initial_guess_plot, altitude_bins/1000,\n",
    "            color='C2', linewidth=2, label = 'Initial Guess')\n",
    "\n",
    "    # Plot final guess\n",
    "    ax.plot(final_guess_plot, altitude_bins/1000,\n",
    "            color='C1', linewidth=2, label = 'Final Guess')\n",
    "    \n",
    "    ax.plot(np.sqrt(abs(dq_estimate/alphas)), altitude_bins/1000,\n",
    "            color='red')\n",
    "    \n",
    "    #ax.set_xlim(1e9, 1e12)\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    \n",
    "    fig_filename = (output_dir + 'e-density-'\n",
    "                    + str(run_time.date())\n",
    "                    + '_' + str(run_time.hour).zfill(2)\n",
    "                    + '-' + str(run_time.minute).zfill(2)\n",
    "                    + '-' + str(run_time.second).zfill(2)\n",
    "                    + '.jpg')\n",
    "    plt.savefig(fig_filename, dpi=150)\n",
    "    \n",
    "    # Close the figure\n",
    "    #...axis\n",
    "    plt.cla()\n",
    "    #...figure\n",
    "    plt.clf()\n",
    "    #...figure windows\n",
    "    plt.close('all')\n",
    "    #...clear memory\n",
    "    gc.collect()\n",
    "\n",
    "def save_inversion_numflux_plot(inversion_results, run_time, output_dir):\n",
    "    \"\"\"Function to create and save a plot of the inversion \n",
    "    energy spectrum.\n",
    "    INPUT\n",
    "    inversion_results\n",
    "        type: dictionary\n",
    "        about: dictionary of inversion results\n",
    "    run_time\n",
    "        type: datetime\n",
    "        about: time to create plot for\n",
    "    output_dir\n",
    "        type: str\n",
    "        about: where to store the images\n",
    "    OUTPUT\n",
    "    none\n",
    "    \"\"\"\n",
    "    # Get energy values\n",
    "    energy_bins = inversion_results[run_time]['energy_bins']\n",
    "    \n",
    "    # Get modeled number flux values\n",
    "    num_flux = inversion_results[run_time]['modeled_flux']\n",
    "    \n",
    "    # Get differential number flux by multiplying by energy bin width\n",
    "    bin_widths = energy_bins - np.roll(energy_bins, shift=1)\n",
    "    \n",
    "    # Fix first value\n",
    "    bin_widths[0] = energy_bins[0] - 0\n",
    "    \n",
    "    num_flux = num_flux*bin_widths\n",
    "    \n",
    "    # Get reduced chi2\n",
    "    chi2 = inversion_results[run_time]['chi2']\n",
    "    dof = inversion_results[run_time]['dof']\n",
    "    reduced_chi2 = chi2/dof\n",
    "\n",
    "    # Plot figure of energy spectrum\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Titles and axis labels\n",
    "    ax.set_title(str(run_time) + r' $\\chi^2_{red}=$' \n",
    "                 + str(round(reduced_chi2, 2)),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "    ax.set_ylabel(r'Number Flux [m$^{-2}$ s$^{-1}$ eV$^{-1}$]',\n",
    "                  fontsize=14)\n",
    "    ax.set_xlabel('Energy [eV]', fontsize=14)\n",
    "\n",
    "    # Axis\n",
    "    ax.tick_params(axis='x', which='major', labelsize=14)\n",
    "    ax.tick_params(axis='y', which='major', labelsize=14)\n",
    "\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "    # Plot the energy\n",
    "    ax.plot(energy_bins, num_flux)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fig_filename = (output_dir + 'number-flux-'\n",
    "                    + str(run_time.date())\n",
    "                    + '_' + str(run_time.hour).zfill(2)\n",
    "                    + '-' + str(run_time.minute).zfill(2)\n",
    "                    + '-' + str(run_time.second).zfill(2)\n",
    "                    + '.jpg')\n",
    "    plt.savefig(fig_filename, dpi=150)\n",
    "    \n",
    "    # Close the figure\n",
    "    #...axis\n",
    "    plt.cla()\n",
    "    #...figure\n",
    "    plt.clf()\n",
    "    #...figure windows\n",
    "    plt.close('all')\n",
    "    #...clear memory\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f96ad0bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: gledhill\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'correction_fade_selector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_64731/741763104.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m         (utc_time, unix_time, \n\u001b[1;32m     33\u001b[0m          \u001b[0mpfisr_altitude\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m          e_density, de_density) = get_isr_data(pfisr_filename, pfisr_data_dir)\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Find indices of interest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_64731/2369945828.py\u001b[0m in \u001b[0;36mget_isr_data\u001b[0;34m(pfisr_filename, pfisr_data_dir)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;31m# Fade from 1 to 0 over 90 to 120km\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0mfade_selector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpfisr_altitude\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlow_fade\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpfisr_altitude\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mhigh_fade\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m     \u001b[0mfade_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrection_fade_selector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcorrection_fade_selector\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m     \u001b[0mfade\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfade_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'correction_fade_selector' is not defined"
     ]
    }
   ],
   "source": [
    "# In[4]:\n",
    "\n",
    "\n",
    "# Read in file with energy dissipation function\n",
    "lambda_filename = 'semeter_kamalabadi_lambda_function.txt'\n",
    "lambda_data = np.loadtxt(lambda_filename, skiprows=5)\n",
    "\n",
    "# Create an interpolated function from this\n",
    "#...values outside set to 0\n",
    "lambda_interp = interp1d(lambda_data[:, 0], lambda_data[:, 1],\n",
    "                         bounds_error=False, fill_value=0)\n",
    "\n",
    "# Read in file with pulsating aurora dates, times and types\n",
    "pa_database = np.loadtxt(reference_file, delimiter='\\t', dtype=str)\n",
    "pa_database = pa_database[1:, :]\n",
    "\n",
    "# Convert dates to datetimes\n",
    "pa_dates = np.array([dt.strptime(d, '%Y-%m-%d').date() for d \n",
    "                     in pa_database[:, 0]])\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "for alpha_type in ['gledhill']:\n",
    "    \n",
    "    print('Starting:', alpha_type)\n",
    "    \n",
    "    for pfisr_filename in pfisr_files:\n",
    "\n",
    "        # Read in the pfisr data\n",
    "        (utc_time, unix_time, \n",
    "         pfisr_altitude,\n",
    "         e_density, de_density) = get_isr_data(pfisr_filename, pfisr_data_dir)\n",
    "\n",
    "        # Find indices of interest\n",
    "        slices_n = find_event_indices(utc_time)\n",
    "\n",
    "        # Create a dictionary to store inversion results in\n",
    "        inversion_results = {}\n",
    "\n",
    "        # Make a directory to store plots and dictionary if it doesn't \n",
    "        #...already exist\n",
    "        if not os.path.exists(save_dir + alpha_type + '/'):\n",
    "            os.mkdir(save_dir + alpha_type + '/')\n",
    "\n",
    "        output_dir = (save_dir + alpha_type + '/' \n",
    "                      + str(utc_time[0].date()) + '/')\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.mkdir(output_dir)\n",
    "\n",
    "        print(str(utc_time[0].date()))\n",
    "\n",
    "        for slice_n in slices_n:\n",
    "\n",
    "            run_time = utc_time[slice_n]\n",
    "\n",
    "            # Get MSIS calculated densities\n",
    "            try:\n",
    "                (total_msis_alt,\n",
    "                 msis_interp_density) = get_msis_density(run_time, \n",
    "                                                    altitude_bins,\n",
    "                                                    max_alt=max_msis_alt,\n",
    "                                                    glat=pfrr_lat,\n",
    "                                                    glon=pfrr_lon)\n",
    "            except Exception as e:\n",
    "                print('Issue with MSIS model.', e)\n",
    "                continue\n",
    "\n",
    "            # Get density for altitude bins\n",
    "            total_msis_density = msis_interp_density(total_msis_alt)\n",
    "            density_rho = msis_interp_density(altitude_bins)\n",
    "\n",
    "\n",
    "            # Calculate mass distance (s) for each altitude \n",
    "            #...by integrating out to 1000 km (~infinity)\n",
    "            s = np.array([mass_distance(z) for z \n",
    "                          in range(len(altitude_bins))])\n",
    "\n",
    "\n",
    "            # Calculate ion production rate for each energy and store\n",
    "            #...in dictionary\n",
    "            ion_prod_rate = {}\n",
    "\n",
    "            for i, energy in enumerate(energy_bins):\n",
    "\n",
    "                # Calculate range-energy value\n",
    "                R = barrett_hays_range_energy_func(energy)\n",
    "\n",
    "                # Get the (s/R)(z) for the energy\n",
    "                s_R = s/R\n",
    "\n",
    "                # Use s/R to get Lambda function values\n",
    "                lambda_vals = lambda_interp(s_R)\n",
    "\n",
    "                # Use all of this to calculate ion production rate \n",
    "                #...as function of alt\n",
    "                q = (lambda_vals * density_rho * energy * F) / (35.5 * R)\n",
    "\n",
    "                # Write to dictionary\n",
    "                ion_prod_rate[energy] = q\n",
    "\n",
    "            # Construct the A matrix\n",
    "            matrix_A = np.zeros([len(altitude_bins),\n",
    "                                 len(energy_bins)])\n",
    "\n",
    "            # Loop through each energy value\n",
    "            for j in range(len(energy_bins)):\n",
    "\n",
    "                # Get the size of the energy bin\n",
    "                #...first bin is from zero to energy\n",
    "                if j == 0:\n",
    "                    delta_E = energy_bins[j] - 0\n",
    "                else:\n",
    "                    delta_E = energy_bins[j] - energy_bins[j-1]\n",
    "\n",
    "                # Set column of matrix\n",
    "                matrix_A[:, j] = ion_prod_rate[energy_bins[j]]*(delta_E/F)\n",
    "\n",
    "            # Get estimated ion production rate and error \n",
    "            #...from isr measurements\n",
    "            try:\n",
    "                (q_estimate, \n",
    "                 dq_estimate,\n",
    "                 alphas) = isr_ion_production_rate(slice_n,\n",
    "                                                   alpha_type=alpha_type)\n",
    "            except:\n",
    "                print('Issue with ion production rate calculation.')\n",
    "                continue\n",
    "\n",
    "            # Make an initial guess of the number flux\n",
    "            initial_num_flux = estimate_initial_number_flux(energy_bins,\n",
    "                                                            matrix_A)\n",
    "            try:\n",
    "                # Perform the maximum entropy iterative process\n",
    "                (new_num_flux,\n",
    "                 chi_square,\n",
    "                 dof,\n",
    "                 converged) = maximum_entropy_iteration(initial_num_flux,\n",
    "                                                        altitude_bins,\n",
    "                                                        energy_bins,\n",
    "                                                        matrix_A,\n",
    "                                                        q_estimate, \n",
    "                                                        dq_estimate)\n",
    "            except:\n",
    "                print('Issue with MEM.')\n",
    "                continue\n",
    "\n",
    "            # Write data to dictionary\n",
    "            d = {'altitude' : altitude_bins,\n",
    "                 'initial_density' : np.sqrt(np.dot(matrix_A,\n",
    "                                                initial_num_flux)/alphas),\n",
    "                 'modeled_density' : np.sqrt(np.dot(matrix_A,\n",
    "                                                new_num_flux)/alphas),\n",
    "                 'measured_density' : np.sqrt(q_estimate/alphas),\n",
    "                 'energy_bins' : energy_bins,\n",
    "                 'modeled_flux' : new_num_flux,\n",
    "                 'chi2' : chi_square,\n",
    "                 'dof' : dof,\n",
    "                 'converged' : converged,\n",
    "                 'units' : 'Values given in meters, seconds, electron-volts.'\n",
    "                }\n",
    "\n",
    "            inversion_results[run_time] = d\n",
    "\n",
    "            # Plot the results and save to output directory\n",
    "            if slice_n%1 == 0:\n",
    "                save_inversion_density_plot(inversion_results,\n",
    "                                            run_time, output_dir)\n",
    "                save_inversion_numflux_plot(inversion_results,\n",
    "                                            run_time, output_dir)\n",
    "\n",
    "            # Clear temporary files in /dev/shm directory in Linux\n",
    "            try:\n",
    "                os.system('rm /dev/shm/*')\n",
    "            except Exception as e: print(e)\n",
    "\n",
    "\n",
    "        # Write the dictionary with inversion data to a pickle file\n",
    "        with open(output_dir + 'inversion-data-' + str(utc_time[0].date()) \n",
    "                  + '.pickle', 'wb') as handle:\n",
    "            pickle.dump(inversion_results, handle,\n",
    "                        protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        print('Finished!')\n",
    "\n",
    "    print('Finished with: ', alpha_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5367da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
