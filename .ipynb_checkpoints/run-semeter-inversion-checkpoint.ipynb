{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf554820",
   "metadata": {},
   "source": [
    "# Code to run electon density -> energy inversion as per Semeter, Kamalabadi 2005 for PFISR data for specified number of days\n",
    "\n",
    "written by Riley Troyer Fall 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9e637a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'ignore', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Libraries\n",
    "from datetime import datetime as dt\n",
    "import gc\n",
    "import h5py\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors\n",
    "import msise00\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.integrate import trapezoid\n",
    "\n",
    "# Disable divide by zero numpy warnings\n",
    "np.seterr(divide='ignore')\n",
    "np.seterr(invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8be960de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in config file with dictionary of specified inputs\n",
    "import config_2021_10_03 as config\n",
    "config_data = config.run_info['config_info']\n",
    "\n",
    "# Path to pfisr data directory\n",
    "pfisr_data_dir = config_data['isr_data_dir']\n",
    "\n",
    "# Get location of PFISR\n",
    "pfrr_lat = config_data['isr_lat']\n",
    "pfrr_lon = config_data['isr_lon']\n",
    "\n",
    "# Define test flux in m^-2 s^-1\n",
    "F = config_data['test_flux']\n",
    "\n",
    "# Don't use PFISR data below this altitude in km\n",
    "pfisr_min_alt = config_data['isr_min_alt']\n",
    "\n",
    "# Get sensitivity limit of PFISR\n",
    "pfisr_sensitivity = config_data['isr_sensitivity']\n",
    "\n",
    "# Parameters for smoothing PFISR data\n",
    "pfisr_smooth_window = config_data['isr_smooth_window']\n",
    "pfisr_smooth_poly_order = config_data['isr_smooth_poly_order']\n",
    "\n",
    "# Altitude in meters to approximate infinity when calculating\n",
    "#...mass distance\n",
    "max_msis_alt = config_data['max_msis_alt']\n",
    "\n",
    "# Maximum number of iterations to run maximum entropy process on\n",
    "max_iterations = config_data['max_iterations']\n",
    "\n",
    "# Reduced chi square to aim for\n",
    "good_fit = config_data['reduced_chi_square']\n",
    "\n",
    "# Define arrays for altitude and energy bins\n",
    "\n",
    "# Altitude in meters\n",
    "#...number of points should be around the same as pfisr data\n",
    "altitude_bins = config_data['altitude_bins']\n",
    "\n",
    "# Energies in eV\n",
    "#...should probably be less than altitude bins to avoid overfitting\n",
    "energy_bins = config_data['energy_bins']\n",
    "\n",
    "# Get files to run code for\n",
    "pfisr_files = config.run_info['run_files']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5e795b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions used in program. Alphabetically.\n",
    "\n",
    "def barrett_hays_range_energy_func(K):\n",
    "    \"\"\"Function to define mass range of electron in air for a specific\n",
    "    energy K in eV. From Barett & Hays 1976\n",
    "    INPUT\n",
    "    K\n",
    "        type: float\n",
    "        about: energy of electron in eV\n",
    "    OUTPUT\n",
    "    R\n",
    "        type: float\n",
    "        about: mass range of particle in kg m^-2 \n",
    "    \"\"\"\n",
    "    # Convert energy to keV to match formula\n",
    "    K = K/1000\n",
    "    \n",
    "    # Range function\n",
    "    R = 4.3e-7 + 5.36e-6 * K**(1.67) - 0.38e-8 * K**(-0.7)\n",
    "    \n",
    "    # Convert R from g/cm^2 to kg/m^2\n",
    "    R = R * 10\n",
    "    \n",
    "    return R\n",
    "\n",
    "def estimate_initial_number_flux(energy_bins, matrix_A):\n",
    "    \"\"\"Function to estimate the intial number flux for each energy bin\n",
    "    INPUT\n",
    "    energy_bins\n",
    "        type: array of float\n",
    "        about: energy values defining energy bins\n",
    "    matrix_A\n",
    "        type: array of float\n",
    "        about: inversion matrix\n",
    "    OUTPUT\n",
    "    initial_num_flux\n",
    "        type: array of float\n",
    "        about: estimated number flux in m^-2 s^-1 for each energy bin\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make an initial guess of the number flux\n",
    "    initial_num_flux = np.ones(len(energy_bins))*(1e12/len(energy_bins))\n",
    "\n",
    "    # Divide by energy bin widths\n",
    "    bin_widths = energy_bins - np.roll(energy_bins, shift=1)\n",
    "\n",
    "    # Fix first value\n",
    "    bin_widths[0] = energy_bins[0] - 0\n",
    "\n",
    "    # Set initial guess\n",
    "    initial_num_flux = initial_num_flux/bin_widths\n",
    "\n",
    "    # If full column of A matrix is zero set initial flux to zero\n",
    "    for j in range(len(energy_bins)):\n",
    "\n",
    "        if np.sum(matrix_A[:, j]) == 0:\n",
    "            initial_num_flux[j] = 0\n",
    "            \n",
    "    return initial_num_flux\n",
    "\n",
    "def get_isr_data(pfisr_filename, pfisr_data_dir):\n",
    "    \"\"\"Function to get relevant data from PFISR datafile.\n",
    "    INPUT\n",
    "    pfisr_filename\n",
    "        type: str\n",
    "        about: data file name, should be .h5 file\n",
    "    pfisr_data_dir\n",
    "        type: str\n",
    "        about: directory where isr data is stored\n",
    "    OUTPUT\n",
    "    utc_time\n",
    "        type: array of datetimes\n",
    "        about: time stamp for each measurement\n",
    "    pfisr_altitude\n",
    "        type: array of float\n",
    "        about: altitude stamp for each measurement in meters\n",
    "    e_density\n",
    "        type: array of float\n",
    "        about: electron number density in m^-3\n",
    "    de_density\n",
    "        type: array of float\n",
    "        about: error in number density\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read in the h5 file\n",
    "    pfisr_file = h5py.File(pfisr_data_dir + pfisr_filename, 'r')\n",
    "\n",
    "    # Get the different beams and select specified angle\n",
    "    beam_angle = 90\n",
    "    beams = np.array(pfisr_file['BeamCodes'])\n",
    "\n",
    "    # Get the beam with a 90 degree elevation angle\n",
    "    indexes = np.linspace(0, len(beams)-1, len(beams))\n",
    "    beam_num = int(indexes[np.abs(beams[:,2] - beam_angle) == 0][0])\n",
    "\n",
    "    # Get time and convert to utc datetime\n",
    "    unix_time = np.array(pfisr_file['Time']['UnixTime'])[:,0]\n",
    "    utc_time = np.array([dt.utcfromtimestamp(d) for d in unix_time])\n",
    "\n",
    "    # Get the altitude array\n",
    "    pfisr_altitude = np.array(pfisr_file['NeFromPower']\n",
    "                              ['Altitude'])[beam_num, :]\n",
    "\n",
    "    # Get the uncorrected number density array\n",
    "    e_density = np.array(pfisr_file['NeFromPower']\n",
    "                         ['Ne_NoTr'])[:, beam_num, :]\n",
    "\n",
    "    # Take the transpose\n",
    "    e_density = np.transpose(e_density)\n",
    "    \n",
    "    # Smooth the electron density\n",
    "    window = pfisr_smooth_window\n",
    "    poly_order = pfisr_smooth_poly_order\n",
    "    e_density = savgol_filter(e_density, window, poly_order,\n",
    "                              axis=0)\n",
    "    \n",
    "    # Find the noise floor by averaging between 55km and 60km\n",
    "    #...assume this should be zero\n",
    "    noise_floor = np.mean(e_density[(pfisr_altitude > 55000)\n",
    "                                    & (pfisr_altitude < 60000), :],\n",
    "                          axis=0)\n",
    "    \n",
    "    # Loop through each column and subtract off noise floor\n",
    "    for j in range(e_density.shape[1]):\n",
    "        e_density[:, j] = e_density[:, j] - noise_floor[j]\n",
    "    \n",
    "    # Get error values\n",
    "    de_density = np.array(pfisr_file['NeFromPower']\n",
    "                          ['errNe_NoTr'])[:, beam_num, :]\n",
    "    de_density = np.transpose(de_density)\n",
    "    \n",
    "    # Trying to figure out how to adjust errors based on smoothing\n",
    "    adjustment = np.sqrt((3 * (3 * window**2 - 7))\n",
    "                         /(4 * window * (window**2 - 4)))\n",
    "    \n",
    "    de_density = de_density * adjustment\n",
    "\n",
    "    # Close file\n",
    "    pfisr_file.close()\n",
    "    \n",
    "    return utc_time, pfisr_altitude, e_density, de_density\n",
    "\n",
    "def get_msis_density(run_time, altitude_bins, max_alt=1001e3,\n",
    "                     glat=65.117, glon=212.540):\n",
    "    \"\"\"Function to get MSIS calculated atmospheric densities.\n",
    "    DEPENDENCIES\n",
    "        msise00, numpy, scipy.interpolate.interp1d\n",
    "    INPUT\n",
    "    run_time\n",
    "        type: datetime\n",
    "        about: time to run msis code for\n",
    "    altitudes\n",
    "        type: array of floats\n",
    "        about: altitudes in meters to run msis code for\n",
    "    max_alt = 1001e3\n",
    "        type: float\n",
    "        about: maximum altitude in meters to run msis for. \n",
    "               Function creates a high altitude log spaced array\n",
    "               between the max of altitudes and the max_alt value.\n",
    "               This is primarily for approximating an indefinite integral.\n",
    "    OUTPUT\n",
    "    total_msis_alt\n",
    "        type: array of floats\n",
    "        about: altitudes values in meters including original array and\n",
    "               high altitude array\n",
    "    msis_interp_density\n",
    "        type: scipy.interplate function\n",
    "        about: 1d interpolation of msis density spanning entire altitude\n",
    "               range.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Run msis for lower altitudes\n",
    "    msis_run_low = msise00.run(time=run_time, altkm=altitude_bins/1000,\n",
    "                               glat=pfrr_lat, glon=pfrr_lon)\n",
    "\n",
    "    # Define a higher altitude array\n",
    "    msis_alt_high = np.logspace(np.log10(max(altitude_bins)+1),\n",
    "                                np.log10(max_alt), 20)\n",
    "    \n",
    "    # Run msis for these higher altitudes\n",
    "    msis_run_high = msise00.run(time=run_time, altkm=msis_alt_high/1000,\n",
    "                               glat=pfrr_lat, glon=pfrr_lon)\n",
    "\n",
    "    # Get total density data\n",
    "    msis_density_low = msis_run_low['Total'].data[0, :, 0, 0]\n",
    "    msis_density_high = msis_run_high['Total'].data[0, :, 0, 0]\n",
    "\n",
    "    # Combine altitude and densities from low and high altitudes\n",
    "    total_msis_alt = np.concatenate((altitude_bins, msis_alt_high))\n",
    "    total_msis_density = np.concatenate((msis_density_low,\n",
    "                                         msis_density_high))\n",
    "\n",
    "    # Create a scipy interpolation function to define density v. altitude\n",
    "    msis_interp_density = interp1d(total_msis_alt, total_msis_density)\n",
    "    \n",
    "    return total_msis_alt, msis_interp_density\n",
    "\n",
    "def isr_ion_production_rate(slice_n):\n",
    "    \"\"\"Function to estimate the ion production rate from isr measurements\n",
    "    INPUT\n",
    "    slice_n\n",
    "        type: integer\n",
    "        about: data slice of isr data to take\n",
    "    OUTPUT\n",
    "    q_estimate\n",
    "        type: array of float\n",
    "        about: estimated ion production rate m^-2 s^-1\n",
    "    dq_estimate\n",
    "        type: array of float\n",
    "        about: error in ion production rate\n",
    "    alphas\n",
    "        type: array of float\n",
    "        about: recombination coefficients\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read in density and errors in those measurements for specific time\n",
    "    e_density_slice = e_density[:, slice_n]\n",
    "    de_density_slice = de_density[:, slice_n]\n",
    "\n",
    "    # Make an interpolation model of this data with respect to altitude\n",
    "    #...but only do this for altitudes > defined minimum value,\n",
    "    #...below this data can be weird\n",
    "    pfisr_density_interp = interp1d(pfisr_altitude, e_density_slice)\n",
    "\n",
    "    # Same interpolation except for error in density\n",
    "    pfisr_error_interp = interp1d(pfisr_altitude, de_density_slice)\n",
    "\n",
    "    # Calculate all recombination coeffcients\n",
    "    alphas = np.array([recombination_coeff(z/1000) for z \n",
    "                       in altitude_bins])\n",
    "\n",
    "    # Multiply by pfisr density to get an estimate of ion production rate\n",
    "    q_estimate = alphas * pfisr_density_interp(altitude_bins)**2\n",
    "\n",
    "    # Get error dq = 2*alpha*n*dn\n",
    "    dq_estimate = (2 * alphas * pfisr_density_interp(altitude_bins)\n",
    "                   * pfisr_error_interp(altitude_bins))\n",
    "    \n",
    "#     # Value below specified height km, assume are zero below data can be off\n",
    "#     q_estimate[altitude_bins < pfisr_min_alt] = 0\n",
    "    \n",
    "#     # Also anywhere where error is larger than value set to zero\n",
    "#     q_estimate[q_estimate <= dq_estimate] = 0\n",
    "    \n",
    "    return q_estimate, dq_estimate, alphas\n",
    "\n",
    "def mass_distance(z_i, I=0):\n",
    "    \"\"\"Function to mass distance of particle traveling some distance\n",
    "    into the atmosphere. Denoted s in the derivations.\n",
    "    Using trapezoid rule for this, which seems to be good enough\n",
    "    INPUT\n",
    "    z\n",
    "        type: int\n",
    "        about: index of altitude that particle reached to\n",
    "    I=0\n",
    "        type: float\n",
    "        about: angle of magnetic inclination at measuring site in radians\n",
    "    OUTPUT\n",
    "    s\n",
    "        type: float\n",
    "        about: mass distance in kg m^-2\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate mass distance traveled \n",
    "    s = (1/np.cos(I)) * trapezoid(total_msis_density[z_i:],\n",
    "                                  total_msis_alt[z_i:])\n",
    "    \n",
    "    return s\n",
    "\n",
    "def maximum_entropy_iteration(initial_num_flux, altitude_bins, energy_bins,\n",
    "                               matrix_A, q_estimate, dq_estimate):\n",
    "    \"\"\"Function to peform the maximum entropy iterative process to approximate\n",
    "    inversion of matrix A. Process is outlined in Semeter & Kamalabadi 2005.\n",
    "    INPUT\n",
    "    initial_num_flux\n",
    "        type: array of float\n",
    "        about: initial guess of number flux for each energy bin in m^-2 s^-1\n",
    "    altitude_bins\n",
    "        type: array of float\n",
    "        about: altitude values in meters defining altitude bins\n",
    "    energy_bins\n",
    "        type: array of float\n",
    "        about: energy values in eV defining energy bins\n",
    "    matrix_A\n",
    "        type: array of float\n",
    "        about: matrix that iteration is trying to invert\n",
    "    q_estimate\n",
    "        type: array of float\n",
    "        about: estimated ion production rate from ISR m^-2 s^-1\n",
    "    dq_estimate\n",
    "        type: array of float\n",
    "        about: error in ion production rate of ISR\n",
    "    OUTPUT\n",
    "    new_num_flux\n",
    "        type: array of float\n",
    "        about: estimated number flux for energy bins in m^-2 s^-1\n",
    "    reduced_chi_square\n",
    "        type: float\n",
    "        about: error in modeled fit\n",
    "    good_alt_index\n",
    "        type: int\n",
    "        about: lower than this won't be good data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set previous value to initial at start\n",
    "    old_num_flux = initial_num_flux\n",
    "    new_num_flux = np.zeros(len(initial_num_flux))  \n",
    "    \n",
    "    # Create array to store all minimum j values\n",
    "    min_js = np.zeros(len(altitude_bins), dtype=int)\n",
    "\n",
    "    # Find all nonzero indices of A matrix\n",
    "    nonzero_args = np.argwhere(matrix_A > 0)\n",
    "\n",
    "    for i in range(len(min_js)):\n",
    "\n",
    "        non_zeros = nonzero_args[nonzero_args[:, 0] == i]\n",
    "\n",
    "        # If there are no non zero values in row, then set to \n",
    "        #...first instance\n",
    "        if len(non_zeros) == 0:\n",
    "            min_js[i] = 0\n",
    "\n",
    "        # Otherwise find the minimum j\n",
    "        else:\n",
    "            min_js[i] = min(non_zeros[:, 1])\n",
    "\n",
    "    # Find the index past which A is defined for altitudes\n",
    "    good_alt_index = np.argwhere(min_js>0)[0][0]\n",
    "\n",
    "    # Run interations until chi2 < specified value\n",
    "    reduced_chi_square = 10\n",
    "\n",
    "    # Or count < specified amount\n",
    "    count = 0\n",
    "\n",
    "    while (reduced_chi_square > good_fit):\n",
    "\n",
    "        # Check count\n",
    "        if count > max_iterations:\n",
    "            print('Slice: {slice_n}. '\n",
    "                  'Unable to converge. '\n",
    "                  'Max iterations reached with chi2 = {chi2}'\n",
    "                  .format(slice_n=slice_n,\n",
    "                          chi2=round(reduced_chi_square, 2)))\n",
    "            break\n",
    "\n",
    "        # Construct the t vector\n",
    "        t = 1/np.dot(matrix_A[:, min_js], old_num_flux[min_js])\n",
    "\n",
    "        # Adjust for infinite values in regions without a nonzero j\n",
    "        t[t == np.inf] = 0        \n",
    "\n",
    "        for j in range(len(energy_bins)):\n",
    "\n",
    "            # Construct c vector\n",
    "            frac = np.inner(matrix_A, old_num_flux)/q_estimate\n",
    "            c = 20 * (1 - frac) * t\n",
    "\n",
    "            # Account for nan and infinite values\n",
    "            #...this is why warning is raised\n",
    "            c[np.isnan(c)] = 0\n",
    "            c[c == -np.inf] = 0\n",
    "            c[c == np.inf] = 0\n",
    "\n",
    "            # Define w constant\n",
    "            w = np.ones(len(altitude_bins))/len(altitude_bins)\n",
    "\n",
    "            # Summation of matrix elements\n",
    "            i_sum = np.sum(w*c*matrix_A[:, j])\n",
    "\n",
    "            # New guess\n",
    "            new_num_flux[j] = old_num_flux[j]/(1-old_num_flux[j]*i_sum)\n",
    "\n",
    "        # Check chi squared, but only on altitudes that A is defined for\n",
    "        diff=q_estimate-np.dot(matrix_A, new_num_flux)\n",
    "        chi_square_array = diff**2/dq_estimate**2\n",
    "\n",
    "        # Set undefined values to zero\n",
    "        chi_square_array[np.isnan(chi_square_array)] = 0\n",
    "        chi_square_array[chi_square_array == np.inf] = 0\n",
    "        chi_square_array[chi_square_array == -np.inf] = 0\n",
    "\n",
    "        # Get the chi squared value\n",
    "        chi_square = np.sum(chi_square_array)\n",
    "\n",
    "        # And the reduced chi square, which should be around 1\n",
    "        reduced_chi_square = chi_square/(len(diff)-1)\n",
    "        \n",
    "        # If reduced chi square less than 1 report and stop\n",
    "        if reduced_chi_square < 1:\n",
    "            print('Slice: {slice_n}. '\n",
    "                  'Possible overfitting. Stopping. '\n",
    "                  'chi2 = {chi2}'\n",
    "                  .format(slice_n=slice_n,\n",
    "                          chi2=round(reduced_chi_square, 2)))\n",
    "            break\n",
    "\n",
    "        # Set old value to new\n",
    "        old_num_flux = np.copy(new_num_flux)\n",
    "\n",
    "        # Set count\n",
    "        count = count + 1\n",
    "\n",
    "    if (count < max_iterations) & (reduced_chi_square >= 1):\n",
    "        print('Slice: {slice_n}. '\n",
    "              'Convergence reached. '\n",
    "              'Iterations: {count}'.format(slice_n=slice_n,\n",
    "                                           count=count-1))\n",
    "        \n",
    "    return new_num_flux, reduced_chi_square, good_alt_index\n",
    "\n",
    "def recombination_coeff(z):\n",
    "    \"\"\"Function defining recombination coefficient\n",
    "    INPUT\n",
    "    z\n",
    "        type:float\n",
    "        about: altitude in kilometers\n",
    "    OUTPUT\n",
    "    alpha\n",
    "        type: float\n",
    "        about: recombination coefficient in m^3/s\n",
    "    \"\"\"\n",
    "    \n",
    "    alpha = 2.5e-12 * np.exp(-z/51.2)\n",
    "    \n",
    "    return alpha\n",
    "\n",
    "def save_inversion_density_plot(inversion_results, run_time, output_dir):\n",
    "    \"\"\"Function to create and save a plot of the inversion \n",
    "    electron density.\n",
    "    INPUT\n",
    "    inversion_results\n",
    "        type: dictionary\n",
    "        about: dictionary of inversion results\n",
    "    run_time\n",
    "        type: datetime\n",
    "        about: time to create plot for\n",
    "    output_dir\n",
    "        type: str\n",
    "        about: where to store the images\n",
    "    OUTPUT\n",
    "    none\n",
    "    \"\"\"\n",
    "    # Get altitude values\n",
    "    altitude_bins=inversion_results[run_time]['altitude']\n",
    "\n",
    "    # Get measured density\n",
    "    pfisr_density_plot = inversion_results[run_time]['measured_density']\n",
    "    pfisr_density_plot = pfisr_density_plot\n",
    "\n",
    "    # Initial guess\n",
    "    initial_guess_plot = inversion_results[run_time]['initial_density']\n",
    "    initial_guess_plot = initial_guess_plot\n",
    "    \n",
    "    # Finally modeled guess\n",
    "    final_guess_plot = inversion_results[run_time]['modeled_density']\n",
    "    final_guess_plot = final_guess_plot\n",
    "    \n",
    "    # Get chi2\n",
    "    reduced_chi2 = inversion_results[run_time]['reduced_chi2']\n",
    "\n",
    "    # Plot figure of initial guess, real data and fit\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Titles and axis labels\n",
    "    ax.set_title(str(run_time) + r' $\\chi^2=$' \n",
    "                 + str(round(reduced_chi2, 2)),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "    ax.set_ylabel('Altitude [km]', fontsize=14)\n",
    "    ax.set_xlabel(r'Electron Density [m$^{-3}$]', fontsize=14)\n",
    "\n",
    "    # Axis\n",
    "    ax.tick_params(axis='x', which='major', labelsize=14)\n",
    "    ax.tick_params(axis='y', which='major', labelsize=14)\n",
    "\n",
    "    ax.set_xscale('log')\n",
    "\n",
    "    # Plot PFISR data\n",
    "    ax.plot(pfisr_density_plot, altitude_bins/1000,\n",
    "            color='k', linewidth=2, label = 'PFISR')\n",
    "\n",
    "    # Plot initial guess\n",
    "    ax.plot(initial_guess_plot, altitude_bins/1000,\n",
    "            color='C2', linewidth=2, label = 'Initial Guess')\n",
    "\n",
    "    # Plot final guess\n",
    "    ax.plot(final_guess_plot, altitude_bins/1000,\n",
    "            color='C1', linewidth=2, label = 'Final Guess')\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fig_filename = (output_dir + 'e-density-'\n",
    "                    + str(run_time.date())\n",
    "                    + '_' + str(run_time.hour).zfill(2)\n",
    "                    + '-' + str(run_time.minute).zfill(2)\n",
    "                    + '-' + str(run_time.second).zfill(2)\n",
    "                    + '.jpg')\n",
    "    plt.savefig(fig_filename, dpi=150)\n",
    "    \n",
    "    # Close the figure\n",
    "    #...axis\n",
    "    plt.cla()\n",
    "    #...figure\n",
    "    plt.clf()\n",
    "    #...figure windows\n",
    "    plt.close('all')\n",
    "    #...clear memory\n",
    "    gc.collect()\n",
    "\n",
    "def save_inversion_numflux_plot(inversion_results, run_time, output_dir):\n",
    "    \"\"\"Function to create and save a plot of the inversion \n",
    "    energy spectrum.\n",
    "    INPUT\n",
    "    inversion_results\n",
    "        type: dictionary\n",
    "        about: dictionary of inversion results\n",
    "    run_time\n",
    "        type: datetime\n",
    "        about: time to create plot for\n",
    "    output_dir\n",
    "        type: str\n",
    "        about: where to store the images\n",
    "    OUTPUT\n",
    "    none\n",
    "    \"\"\"\n",
    "    # Get energy values\n",
    "    energy_bins = inversion_results[run_time]['energy_bins']\n",
    "    \n",
    "    # Get modeled differential number flux values\n",
    "    #...to do this first need energy bin widths\n",
    "    bin_widths = energy_bins - np.roll(energy_bins, shift=1)\n",
    "    #...fix first value\n",
    "    bin_widths[0] = energy_bins[0] - 0\n",
    "    \n",
    "    num_flux = inversion_results[run_time]['modeled_flux']*bin_widths\n",
    "    \n",
    "    # Get chi2\n",
    "    reduced_chi2 = inversion_results[run_time]['reduced_chi2']\n",
    "\n",
    "    # Plot figure of energy spectrum\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Titles and axis labels\n",
    "    ax.set_title(str(run_time) + r' $\\chi^2=$' \n",
    "                 + str(round(reduced_chi2, 2)),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "    ax.set_ylabel(r'Differential Flux'\n",
    "                  r'[m$^{-2}$ s$^{-1}$ eV$^{-1}$]', fontsize=14)\n",
    "    ax.set_xlabel('Energy [eV]', fontsize=14)\n",
    "\n",
    "    # Axis\n",
    "    ax.tick_params(axis='x', which='major', labelsize=14)\n",
    "    ax.tick_params(axis='y', which='major', labelsize=14)\n",
    "\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "\n",
    "    # Plot the energy\n",
    "    ax.plot(energy_bins, num_flux)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fig_filename = (output_dir + 'number-flux-'\n",
    "                    + str(run_time.date())\n",
    "                    + '_' + str(run_time.hour).zfill(2)\n",
    "                    + '-' + str(run_time.minute).zfill(2)\n",
    "                    + '-' + str(run_time.second).zfill(2)\n",
    "                    + '.jpg')\n",
    "    plt.savefig(fig_filename, dpi=150)\n",
    "    \n",
    "    # Close the figure\n",
    "    #...axis\n",
    "    plt.cla()\n",
    "    #...figure\n",
    "    plt.clf()\n",
    "    #...figure windows\n",
    "    plt.close('all')\n",
    "    #...clear memory\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7f25319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in file with energy dissipation function\n",
    "lambda_filename = 'semeter_kamalabadi_lambda_function.txt'\n",
    "lambda_data = np.loadtxt(lambda_filename, skiprows=5)\n",
    "\n",
    "# Create an interpolated function from this\n",
    "#...values outside set to 0\n",
    "lambda_interp = interp1d(lambda_data[:, 0], lambda_data[:, 1],\n",
    "                         bounds_error=False, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2804cb08",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-10-13\n",
      "Slice: 0. Convergence reached. Iterations: 13\n",
      "Slice: 1. Convergence reached. Iterations: 10\n",
      "Slice: 2. Convergence reached. Iterations: 8\n",
      "Slice: 3. Convergence reached. Iterations: 14\n",
      "Slice: 4. Convergence reached. Iterations: 216\n",
      "Slice: 5. Convergence reached. Iterations: 1695\n",
      "Slice: 6. Convergence reached. Iterations: 41\n",
      "Slice: 7. Convergence reached. Iterations: 142\n",
      "Slice: 8. Convergence reached. Iterations: 38\n",
      "Slice: 9. Convergence reached. Iterations: 372\n",
      "Slice: 10. Unable to converge. Max iterations reached with chi2 = 1.13\n",
      "Slice: 11. Convergence reached. Iterations: 89\n",
      "Slice: 12. Convergence reached. Iterations: 3975\n",
      "Slice: 13. Unable to converge. Max iterations reached with chi2 = 2.47\n",
      "Slice: 14. Convergence reached. Iterations: 3886\n",
      "Slice: 15. Unable to converge. Max iterations reached with chi2 = 5.29\n",
      "Slice: 16. Convergence reached. Iterations: 97\n",
      "Slice: 17. Unable to converge. Max iterations reached with chi2 = 1573.74\n",
      "Slice: 18. Convergence reached. Iterations: 226\n",
      "Slice: 19. Unable to converge. Max iterations reached with chi2 = 1.8\n",
      "Slice: 20. Unable to converge. Max iterations reached with chi2 = 2.08\n",
      "Slice: 21. Convergence reached. Iterations: 347\n",
      "Slice: 22. Convergence reached. Iterations: 1013\n",
      "Slice: 23. Convergence reached. Iterations: 14\n",
      "Slice: 24. Convergence reached. Iterations: 7\n",
      "Slice: 25. Convergence reached. Iterations: 22\n",
      "Slice: 26. Convergence reached. Iterations: 5\n",
      "Slice: 27. Convergence reached. Iterations: 0\n",
      "Slice: 28. Unable to converge. Max iterations reached with chi2 = 1.43\n",
      "Slice: 29. Convergence reached. Iterations: 41\n",
      "Slice: 30. Unable to converge. Max iterations reached with chi2 = 1.31\n",
      "Slice: 31. Convergence reached. Iterations: 28\n",
      "Slice: 32. Convergence reached. Iterations: 5\n",
      "Slice: 33. Convergence reached. Iterations: 3\n",
      "Slice: 34. Unable to converge. Max iterations reached with chi2 = 1.97\n",
      "Slice: 35. Unable to converge. Max iterations reached with chi2 = 1.24\n",
      "Slice: 36. Convergence reached. Iterations: 1476\n",
      "Slice: 37. Unable to converge. Max iterations reached with chi2 = 1.93\n",
      "Slice: 38. Convergence reached. Iterations: 474\n",
      "Slice: 39. Unable to converge. Max iterations reached with chi2 = 1.6\n",
      "Slice: 40. Unable to converge. Max iterations reached with chi2 = 1.38\n",
      "Slice: 41. Convergence reached. Iterations: 11\n",
      "Slice: 42. Convergence reached. Iterations: 18\n",
      "Slice: 43. Convergence reached. Iterations: 9\n",
      "Slice: 44. Unable to converge. Max iterations reached with chi2 = 2.57\n",
      "Slice: 45. Unable to converge. Max iterations reached with chi2 = 3.32\n",
      "Slice: 46. Convergence reached. Iterations: 1388\n",
      "Slice: 47. Unable to converge. Max iterations reached with chi2 = 1.91\n",
      "Slice: 48. Convergence reached. Iterations: 40\n",
      "Slice: 49. Convergence reached. Iterations: 257\n",
      "Slice: 50. Unable to converge. Max iterations reached with chi2 = 1.1\n",
      "Slice: 51. Unable to converge. Max iterations reached with chi2 = 1.66\n",
      "Slice: 52. Convergence reached. Iterations: 84\n",
      "Slice: 53. Convergence reached. Iterations: 45\n",
      "Slice: 54. Convergence reached. Iterations: 96\n",
      "Slice: 55. Convergence reached. Iterations: 110\n",
      "Slice: 56. Convergence reached. Iterations: 10\n",
      "Slice: 57. Convergence reached. Iterations: 24\n",
      "Slice: 58. Convergence reached. Iterations: 122\n",
      "Slice: 59. Convergence reached. Iterations: 68\n",
      "Slice: 60. Unable to converge. Max iterations reached with chi2 = 1.13\n",
      "Slice: 61. Unable to converge. Max iterations reached with chi2 = 1.52\n",
      "Slice: 62. Convergence reached. Iterations: 59\n",
      "Slice: 63. Convergence reached. Iterations: 32\n",
      "Slice: 64. Convergence reached. Iterations: 876\n",
      "Slice: 65. Convergence reached. Iterations: 27\n",
      "Slice: 66. Convergence reached. Iterations: 555\n",
      "Slice: 67. Convergence reached. Iterations: 80\n",
      "Slice: 68. Convergence reached. Iterations: 8\n",
      "Slice: 69. Unable to converge. Max iterations reached with chi2 = 1.4\n",
      "Slice: 70. Convergence reached. Iterations: 12\n",
      "Slice: 71. Convergence reached. Iterations: 11\n",
      "Slice: 72. Convergence reached. Iterations: 10\n",
      "Slice: 73. Convergence reached. Iterations: 80\n",
      "Slice: 74. Convergence reached. Iterations: 9\n",
      "Slice: 75. Convergence reached. Iterations: 10\n",
      "Slice: 76. Convergence reached. Iterations: 12\n",
      "Slice: 77. Convergence reached. Iterations: 17\n",
      "Slice: 78. Convergence reached. Iterations: 16\n",
      "Slice: 79. Convergence reached. Iterations: 187\n",
      "Slice: 80. Convergence reached. Iterations: 105\n",
      "Slice: 81. Convergence reached. Iterations: 518\n",
      "Slice: 82. Convergence reached. Iterations: 207\n",
      "Slice: 83. Convergence reached. Iterations: 190\n",
      "Slice: 84. Convergence reached. Iterations: 40\n",
      "Slice: 85. Convergence reached. Iterations: 32\n",
      "Slice: 86. Convergence reached. Iterations: 42\n",
      "Slice: 87. Convergence reached. Iterations: 79\n",
      "Slice: 88. Convergence reached. Iterations: 17\n",
      "Slice: 89. Convergence reached. Iterations: 10\n",
      "Slice: 90. Convergence reached. Iterations: 12\n",
      "Slice: 91. Convergence reached. Iterations: 32\n",
      "Slice: 92. Convergence reached. Iterations: 16\n",
      "Slice: 93. Convergence reached. Iterations: 13\n",
      "Slice: 94. Convergence reached. Iterations: 12\n",
      "Slice: 95. Convergence reached. Iterations: 10\n",
      "Slice: 96. Convergence reached. Iterations: 17\n",
      "Slice: 97. Convergence reached. Iterations: 21\n",
      "Slice: 98. Convergence reached. Iterations: 13\n",
      "Slice: 99. Convergence reached. Iterations: 19\n",
      "Slice: 100. Convergence reached. Iterations: 262\n",
      "Slice: 101. Convergence reached. Iterations: 8\n",
      "Slice: 102. Convergence reached. Iterations: 19\n",
      "Slice: 103. Convergence reached. Iterations: 90\n",
      "Slice: 104. Convergence reached. Iterations: 76\n",
      "Slice: 105. Convergence reached. Iterations: 101\n",
      "Slice: 106. Convergence reached. Iterations: 56\n",
      "Slice: 107. Convergence reached. Iterations: 103\n",
      "Slice: 108. Convergence reached. Iterations: 35\n",
      "Slice: 109. Convergence reached. Iterations: 89\n",
      "Slice: 110. Convergence reached. Iterations: 59\n",
      "Slice: 111. Unable to converge. Max iterations reached with chi2 = 1.13\n",
      "Slice: 112. Convergence reached. Iterations: 27\n",
      "Slice: 113. Convergence reached. Iterations: 826\n",
      "Slice: 114. Convergence reached. Iterations: 4314\n",
      "Slice: 115. Convergence reached. Iterations: 368\n",
      "Slice: 116. Convergence reached. Iterations: 326\n",
      "Slice: 117. Convergence reached. Iterations: 1756\n",
      "Slice: 118. Convergence reached. Iterations: 377\n",
      "Slice: 119. Convergence reached. Iterations: 463\n",
      "Slice: 120. Convergence reached. Iterations: 67\n",
      "Slice: 121. Convergence reached. Iterations: 210\n",
      "Slice: 122. Convergence reached. Iterations: 577\n",
      "Slice: 123. Unable to converge. Max iterations reached with chi2 = 1.05\n",
      "Slice: 124. Unable to converge. Max iterations reached with chi2 = 1.08\n",
      "Slice: 125. Convergence reached. Iterations: 1738\n",
      "Slice: 126. Convergence reached. Iterations: 2132\n",
      "Slice: 127. Convergence reached. Iterations: 373\n",
      "Slice: 128. Convergence reached. Iterations: 57\n",
      "Slice: 129. Convergence reached. Iterations: 30\n",
      "Slice: 130. Convergence reached. Iterations: 4979\n",
      "Slice: 131. Unable to converge. Max iterations reached with chi2 = 1.24\n",
      "Slice: 132. Convergence reached. Iterations: 27\n",
      "Slice: 133. Convergence reached. Iterations: 821\n",
      "Slice: 134. Convergence reached. Iterations: 2448\n",
      "Slice: 135. Convergence reached. Iterations: 475\n",
      "Slice: 136. Convergence reached. Iterations: 359\n",
      "Slice: 137. Convergence reached. Iterations: 4565\n",
      "Slice: 138. Convergence reached. Iterations: 3649\n",
      "Slice: 139. Convergence reached. Iterations: 2043\n",
      "Slice: 140. Convergence reached. Iterations: 1332\n",
      "Slice: 141. Convergence reached. Iterations: 1510\n",
      "Slice: 142. Convergence reached. Iterations: 547\n",
      "Slice: 143. Convergence reached. Iterations: 299\n",
      "Slice: 144. Convergence reached. Iterations: 430\n",
      "Slice: 145. Convergence reached. Iterations: 2220\n",
      "Slice: 146. Convergence reached. Iterations: 954\n",
      "Slice: 147. Convergence reached. Iterations: 638\n",
      "Slice: 148. Convergence reached. Iterations: 564\n",
      "Slice: 149. Convergence reached. Iterations: 2668\n",
      "Slice: 150. Convergence reached. Iterations: 481\n",
      "Slice: 151. Convergence reached. Iterations: 3778\n",
      "Slice: 152. Convergence reached. Iterations: 848\n",
      "Slice: 153. Convergence reached. Iterations: 1848\n",
      "Slice: 154. Convergence reached. Iterations: 982\n",
      "Slice: 155. Convergence reached. Iterations: 1749\n",
      "Slice: 156. Convergence reached. Iterations: 40\n",
      "Slice: 157. Convergence reached. Iterations: 89\n",
      "Slice: 158. Convergence reached. Iterations: 426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice: 159. Convergence reached. Iterations: 78\n",
      "Slice: 160. Convergence reached. Iterations: 164\n",
      "Slice: 161. Convergence reached. Iterations: 27\n",
      "Slice: 162. Convergence reached. Iterations: 222\n",
      "Slice: 163. Convergence reached. Iterations: 623\n",
      "Slice: 164. Convergence reached. Iterations: 28\n",
      "Slice: 165. Convergence reached. Iterations: 563\n",
      "Slice: 166. Convergence reached. Iterations: 6071\n",
      "Slice: 167. Convergence reached. Iterations: 565\n",
      "Slice: 168. Convergence reached. Iterations: 108\n",
      "Slice: 169. Convergence reached. Iterations: 797\n",
      "Slice: 170. Convergence reached. Iterations: 185\n",
      "Slice: 171. Convergence reached. Iterations: 83\n",
      "Slice: 172. Convergence reached. Iterations: 50\n",
      "Slice: 173. Convergence reached. Iterations: 1996\n",
      "Slice: 174. Convergence reached. Iterations: 71\n",
      "Slice: 175. Convergence reached. Iterations: 296\n",
      "Slice: 176. Convergence reached. Iterations: 103\n",
      "Slice: 177. Convergence reached. Iterations: 26\n",
      "Slice: 178. Convergence reached. Iterations: 68\n",
      "Slice: 179. Convergence reached. Iterations: 311\n",
      "Slice: 180. Convergence reached. Iterations: 203\n",
      "Slice: 181. Convergence reached. Iterations: 436\n",
      "Slice: 182. Convergence reached. Iterations: 19\n",
      "Slice: 183. Convergence reached. Iterations: 80\n",
      "Slice: 184. Convergence reached. Iterations: 133\n",
      "Slice: 185. Convergence reached. Iterations: 277\n",
      "Slice: 186. Unable to converge. Max iterations reached with chi2 = 1.18\n",
      "Slice: 187. Convergence reached. Iterations: 110\n",
      "Slice: 188. Convergence reached. Iterations: 463\n",
      "Slice: 189. Convergence reached. Iterations: 633\n",
      "Slice: 190. Convergence reached. Iterations: 212\n",
      "Slice: 191. Convergence reached. Iterations: 352\n",
      "Slice: 192. Convergence reached. Iterations: 187\n",
      "Slice: 193. Unable to converge. Max iterations reached with chi2 = 1.21\n",
      "Slice: 194. Convergence reached. Iterations: 82\n",
      "Slice: 195. Convergence reached. Iterations: 1846\n",
      "Slice: 196. Convergence reached. Iterations: 168\n",
      "Slice: 197. Convergence reached. Iterations: 1085\n",
      "Slice: 198. Convergence reached. Iterations: 329\n",
      "Slice: 199. Convergence reached. Iterations: 52\n",
      "Slice: 200. Convergence reached. Iterations: 68\n",
      "Slice: 201. Convergence reached. Iterations: 107\n",
      "Slice: 202. Convergence reached. Iterations: 230\n",
      "Slice: 203. Convergence reached. Iterations: 81\n",
      "Slice: 204. Convergence reached. Iterations: 17\n",
      "Slice: 205. Convergence reached. Iterations: 64\n",
      "Slice: 206. Convergence reached. Iterations: 68\n",
      "Slice: 207. Convergence reached. Iterations: 178\n",
      "Slice: 208. Convergence reached. Iterations: 19\n",
      "Slice: 209. Convergence reached. Iterations: 17\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "for pfisr_filename in pfisr_files:    \n",
    "    \n",
    "    # Read in the pfisr data\n",
    "    (utc_time, pfisr_altitude,\n",
    "     e_density, de_density) = get_isr_data(pfisr_filename, pfisr_data_dir)\n",
    "\n",
    "    # Create a dictionary to store inversion results in\n",
    "    inversion_results = {}\n",
    "\n",
    "    # Make a directory to store plots and dictionary if it doesn't \n",
    "    #...already exist\n",
    "    output_dir = (pfisr_data_dir + 'semeter-inversion-' \n",
    "                   + str(utc_time[0].date()) + '/')\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "    try:    \n",
    "        print(str(utc_time[0].date()))\n",
    "\n",
    "        for slice_n, run_time in enumerate(utc_time):\n",
    "\n",
    "            # Get MSIS calculated densities\n",
    "            (total_msis_alt,\n",
    "             msis_interp_density) = get_msis_density(run_time, altitude_bins,\n",
    "                                                     max_alt=max_msis_alt,\n",
    "                                                     glat=pfrr_lat, glon=pfrr_lon)\n",
    "\n",
    "            # Get density for altitude bins\n",
    "            total_msis_density = msis_interp_density(total_msis_alt)\n",
    "            density_rho = msis_interp_density(altitude_bins)\n",
    "\n",
    "            # Calculate mass distance (s) for each altitude by integrating\n",
    "            #...out to 1000 km (~infinity)\n",
    "            s = np.array([mass_distance(z) for z in range(len(altitude_bins))])\n",
    "\n",
    "            # Calculate ion production rate for each energy and store\n",
    "            #...in dictionary\n",
    "            ion_prod_rate = {}\n",
    "\n",
    "            for i, energy in enumerate(energy_bins):\n",
    "\n",
    "                # Calculate range-energy value\n",
    "                R = barrett_hays_range_energy_func(energy)\n",
    "\n",
    "                # Get the (s/R)(z) for the energy\n",
    "                s_R = s/R\n",
    "\n",
    "                # Use s/R to get Lambda function values\n",
    "                lambda_vals = lambda_interp(s_R)\n",
    "\n",
    "                # Use all of this to calculate ion production rate as function\n",
    "                #...of alt\n",
    "                q = (lambda_vals * density_rho * energy * F) / (35.5 * R)\n",
    "\n",
    "                # Write to dictionary\n",
    "                ion_prod_rate[energy] = q\n",
    "\n",
    "            # Construct the A matrix\n",
    "            matrix_A = np.zeros([len(altitude_bins), len(energy_bins)])\n",
    "\n",
    "            # Loop through each energy value\n",
    "            for j in range(len(energy_bins)):\n",
    "\n",
    "                # Get the size of the energy bin\n",
    "                #...first bin is from zero to energy\n",
    "                if j == 0:\n",
    "                    delta_E = energy_bins[j] - 0\n",
    "                else:\n",
    "                    delta_E = energy_bins[j] - energy_bins[j-1]\n",
    "\n",
    "                # Set column of matrix\n",
    "                matrix_A[:, j] = ion_prod_rate[energy_bins[j]] * (delta_E/F)\n",
    "\n",
    "            # Get estimated ion production rate and error from isr measurements\n",
    "            q_estimate, dq_estimate, alphas = isr_ion_production_rate(slice_n)\n",
    "\n",
    "            # Make an initial guess of the number flux\n",
    "            initial_num_flux = estimate_initial_number_flux(energy_bins, matrix_A)\n",
    "\n",
    "            # Perform the maximum entropy iterative process\n",
    "            (new_num_flux,\n",
    "             reduced_chi_square,\n",
    "             good_alt_index) = maximum_entropy_iteration(initial_num_flux,\n",
    "                                                         altitude_bins, energy_bins,\n",
    "                                                         matrix_A,\n",
    "                                                         q_estimate, dq_estimate)\n",
    "\n",
    "            # Write data to dictionary\n",
    "            d = {'altitude' : altitude_bins,\n",
    "                 'initial_density' : np.sqrt(np.dot(matrix_A,\n",
    "                                                    initial_num_flux)/alphas),\n",
    "                 'modeled_density' : np.sqrt(np.dot(matrix_A,\n",
    "                                                    new_num_flux)/alphas),\n",
    "                 'measured_density' : np.sqrt(q_estimate/alphas),\n",
    "                 'energy_bins' : energy_bins,\n",
    "                 'modeled_flux' : new_num_flux,\n",
    "                 'reduced_chi2' : reduced_chi_square,\n",
    "                 'units' : 'Values given in meters, seconds, electron-volts.',\n",
    "                 'notes' : 'modeled_flux is differential number flux/eV'\n",
    "                }\n",
    "\n",
    "            inversion_results[run_time] = d\n",
    "\n",
    "            # Plot the results and save to output directory\n",
    "            save_inversion_density_plot(inversion_results, run_time, output_dir)\n",
    "            save_inversion_numflux_plot(inversion_results, run_time, output_dir)\n",
    "\n",
    "        # Write the dictionary with inversion data to a pickle file\n",
    "        with open(output_dir + 'inversion-data-' + str(utc_time[0].date()) \n",
    "                  + '.pickle', 'wb') as handle:\n",
    "            pickle.dump(inversion_results, handle,\n",
    "                        protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        print('Finished!')\n",
    "\n",
    "    except Exception as e: print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca46210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
